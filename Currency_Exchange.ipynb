{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "-fE4YFqbyolK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "8Xyf-WEjywMo"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FWUYxMXny2Lj",
    "outputId": "347ec32c-91d2-4456-88f7-f5e2d46d0f19",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Chg%</th>\n",
       "      <th>NIFTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01-Jan-20</td>\n",
       "      <td>71.227</td>\n",
       "      <td>71.365</td>\n",
       "      <td>71.377</td>\n",
       "      <td>71.225</td>\n",
       "      <td>1.16K</td>\n",
       "      <td>-0.18%</td>\n",
       "      <td>12182.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>02-Jan-20</td>\n",
       "      <td>71.350</td>\n",
       "      <td>71.235</td>\n",
       "      <td>71.408</td>\n",
       "      <td>71.235</td>\n",
       "      <td>4.63K</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>12282.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>03-Jan-20</td>\n",
       "      <td>71.770</td>\n",
       "      <td>71.610</td>\n",
       "      <td>71.844</td>\n",
       "      <td>71.520</td>\n",
       "      <td>7.49K</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>12226.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>06-Jan-20</td>\n",
       "      <td>71.867</td>\n",
       "      <td>72.011</td>\n",
       "      <td>72.123</td>\n",
       "      <td>71.834</td>\n",
       "      <td>7.44K</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>11993.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>07-Jan-20</td>\n",
       "      <td>71.845</td>\n",
       "      <td>71.765</td>\n",
       "      <td>71.923</td>\n",
       "      <td>71.670</td>\n",
       "      <td>6.69K</td>\n",
       "      <td>-0.03%</td>\n",
       "      <td>12052.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       Date   Price    Open    High     Low Volume    Chg%     NIFTY\n",
       "0      1  01-Jan-20  71.227  71.365  71.377  71.225  1.16K  -0.18%  12182.50\n",
       "1      2  02-Jan-20  71.350  71.235  71.408  71.235  4.63K   0.17%  12282.20\n",
       "2      3  03-Jan-20  71.770  71.610  71.844  71.520  7.49K   0.59%  12226.65\n",
       "3      4  06-Jan-20  71.867  72.011  72.123  71.834  7.44K   0.14%  11993.05\n",
       "4      5  07-Jan-20  71.845  71.765  71.923  71.670  6.69K  -0.03%  12052.95"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "7DJliEMZjvKL",
    "outputId": "f90156cd-fadf-422c-d056-260c1598b0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 696 entries, 0 to 695\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   index   696 non-null    int64  \n",
      " 1   Date    696 non-null    object \n",
      " 2   Price   696 non-null    float64\n",
      " 3   Open    696 non-null    float64\n",
      " 4   High    696 non-null    float64\n",
      " 5   Low     696 non-null    float64\n",
      " 6   Volume  696 non-null    object \n",
      " 7   Chg%    696 non-null    object \n",
      " 8   NIFTY   696 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(3)\n",
      "memory usage: 49.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgwW0OiqkHmZ",
    "outputId": "cbe922a0-e7d5-45df-af34-7305cf778de7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>NIFTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>696.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>348.500000</td>\n",
       "      <td>74.774272</td>\n",
       "      <td>74.775737</td>\n",
       "      <td>74.953815</td>\n",
       "      <td>74.612264</td>\n",
       "      <td>14534.659052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>201.062179</td>\n",
       "      <td>1.944422</td>\n",
       "      <td>1.937994</td>\n",
       "      <td>1.952544</td>\n",
       "      <td>1.936294</td>\n",
       "      <td>2839.842186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.710000</td>\n",
       "      <td>70.720000</td>\n",
       "      <td>70.945000</td>\n",
       "      <td>70.682000</td>\n",
       "      <td>7610.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>174.750000</td>\n",
       "      <td>73.466250</td>\n",
       "      <td>73.498500</td>\n",
       "      <td>73.618000</td>\n",
       "      <td>73.293500</td>\n",
       "      <td>11933.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>348.500000</td>\n",
       "      <td>74.520500</td>\n",
       "      <td>74.544000</td>\n",
       "      <td>74.650000</td>\n",
       "      <td>74.340000</td>\n",
       "      <td>15307.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>522.250000</td>\n",
       "      <td>75.694000</td>\n",
       "      <td>75.705000</td>\n",
       "      <td>75.945750</td>\n",
       "      <td>75.492500</td>\n",
       "      <td>17119.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>696.000000</td>\n",
       "      <td>79.990000</td>\n",
       "      <td>80.026000</td>\n",
       "      <td>80.235000</td>\n",
       "      <td>79.892000</td>\n",
       "      <td>18477.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index       Price        Open        High         Low  \\\n",
       "count  696.000000  696.000000  696.000000  696.000000  696.000000   \n",
       "mean   348.500000   74.774272   74.775737   74.953815   74.612264   \n",
       "std    201.062179    1.944422    1.937994    1.952544    1.936294   \n",
       "min      1.000000   70.710000   70.720000   70.945000   70.682000   \n",
       "25%    174.750000   73.466250   73.498500   73.618000   73.293500   \n",
       "50%    348.500000   74.520500   74.544000   74.650000   74.340000   \n",
       "75%    522.250000   75.694000   75.705000   75.945750   75.492500   \n",
       "max    696.000000   79.990000   80.026000   80.235000   79.892000   \n",
       "\n",
       "              NIFTY  \n",
       "count    696.000000  \n",
       "mean   14534.659052  \n",
       "std     2839.842186  \n",
       "min     7610.250000  \n",
       "25%    11933.612500  \n",
       "50%    15307.450000  \n",
       "75%    17119.100000  \n",
       "max    18477.050000  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "UAS7x2tHy3uo"
   },
   "outputs": [],
   "source": [
    "features = [\"Open\",\"High\",\"Low\",\"NIFTY\"]\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "kfauplWoy-lx",
    "outputId": "ad6fc692-3614-40f6-aa8d-7a0112e8249a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>NIFTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.365</td>\n",
       "      <td>71.377</td>\n",
       "      <td>71.225</td>\n",
       "      <td>12182.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.235</td>\n",
       "      <td>71.408</td>\n",
       "      <td>71.235</td>\n",
       "      <td>12282.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.610</td>\n",
       "      <td>71.844</td>\n",
       "      <td>71.520</td>\n",
       "      <td>12226.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.011</td>\n",
       "      <td>72.123</td>\n",
       "      <td>71.834</td>\n",
       "      <td>11993.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.765</td>\n",
       "      <td>71.923</td>\n",
       "      <td>71.670</td>\n",
       "      <td>12052.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High     Low     NIFTY\n",
       "0  71.365  71.377  71.225  12182.50\n",
       "1  71.235  71.408  71.235  12282.20\n",
       "2  71.610  71.844  71.520  12226.65\n",
       "3  72.011  72.123  71.834  11993.05\n",
       "4  71.765  71.923  71.670  12052.95"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2PEnMGZzCf0",
    "outputId": "71024039-1a4a-46e9-9089-c533159e1ab2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 4)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "WO9ryEA0zGk_"
   },
   "outputs": [],
   "source": [
    "y = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "Ht7qyBHud0fD"
   },
   "outputs": [],
   "source": [
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "3LMBCVaAdkY8"
   },
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s20Zg-a7hYk-",
    "outputId": "49942b18-7efc-4916-f524-194d4afb560a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Woogqft2eABE",
    "outputId": "89d2155c-0d79-428d-da7b-bc061ebda9fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (696, 4)\n",
      "y shape: (696, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "ETOhIUUozPUe"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "eqiWMmKWzS6Z"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "HRHRwbzmzXIp"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZtIIMxPzY_Q",
    "outputId": "e9e9e829-5380-479f-b4cc-94aacdfedd8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 67770.7188 - val_loss: 38468.4922\n",
      "Epoch 2/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9607.2822 - val_loss: 601.8428\n",
      "Epoch 3/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1311.3485 - val_loss: 1386.8760\n",
      "Epoch 4/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 513.8057 - val_loss: 75.4745\n",
      "Epoch 5/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 419.1364 - val_loss: 505.8773\n",
      "Epoch 6/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 447.0241 - val_loss: 33.5723\n",
      "Epoch 7/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 422.3454 - val_loss: 141.6300\n",
      "Epoch 8/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 419.0539 - val_loss: 22.3447\n",
      "Epoch 9/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 431.4465 - val_loss: 67.7245\n",
      "Epoch 10/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 386.8447 - val_loss: 90.6982\n",
      "Epoch 11/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 384.7462 - val_loss: 367.7919\n",
      "Epoch 12/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 389.8791 - val_loss: 287.0019\n",
      "Epoch 13/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 376.0644 - val_loss: 445.8120\n",
      "Epoch 14/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 393.7358 - val_loss: 367.4017\n",
      "Epoch 15/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 399.4842 - val_loss: 154.3233\n",
      "Epoch 16/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 350.0246 - val_loss: 463.4342\n",
      "Epoch 17/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 365.9272 - val_loss: 26.1722\n",
      "Epoch 18/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 358.0333 - val_loss: 52.0194\n",
      "Epoch 19/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 361.9237 - val_loss: 358.3961\n",
      "Epoch 20/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 385.9800 - val_loss: 465.3228\n",
      "Epoch 21/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 405.4715 - val_loss: 113.6291\n",
      "Epoch 22/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 367.6421 - val_loss: 185.6522\n",
      "Epoch 23/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 324.0085 - val_loss: 129.1689\n",
      "Epoch 24/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 308.2545 - val_loss: 193.9736\n",
      "Epoch 25/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 302.4740 - val_loss: 16.4995\n",
      "Epoch 26/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 289.3816 - val_loss: 175.9614\n",
      "Epoch 27/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 278.5907 - val_loss: 369.1490\n",
      "Epoch 28/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 271.7905 - val_loss: 75.2471\n",
      "Epoch 29/500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 263.0248 - val_loss: 138.3029\n",
      "Epoch 30/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 357.9661 - val_loss: 31.0938\n",
      "Epoch 31/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 276.2619 - val_loss: 456.2159\n",
      "Epoch 32/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 283.4861 - val_loss: 16.2964\n",
      "Epoch 33/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 253.3694 - val_loss: 59.7168\n",
      "Epoch 34/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 229.2129 - val_loss: 36.3553\n",
      "Epoch 35/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 237.2063 - val_loss: 9.0520\n",
      "Epoch 36/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 223.0368 - val_loss: 267.5309\n",
      "Epoch 37/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 238.5284 - val_loss: 155.8032\n",
      "Epoch 38/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 210.7015 - val_loss: 252.6331\n",
      "Epoch 39/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 187.9492 - val_loss: 19.5250\n",
      "Epoch 40/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 237.8303 - val_loss: 7.3047\n",
      "Epoch 41/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 182.0791 - val_loss: 12.5005\n",
      "Epoch 42/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 162.4896 - val_loss: 20.3560\n",
      "Epoch 43/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 160.4655 - val_loss: 44.6700\n",
      "Epoch 44/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 186.0581 - val_loss: 22.6132\n",
      "Epoch 45/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 169.3602 - val_loss: 6.2345\n",
      "Epoch 46/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 180.1818 - val_loss: 12.3635\n",
      "Epoch 47/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 149.5290 - val_loss: 377.3907\n",
      "Epoch 48/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 151.0503 - val_loss: 148.0925\n",
      "Epoch 49/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 125.1615 - val_loss: 165.3071\n",
      "Epoch 50/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 116.4156 - val_loss: 69.3435\n",
      "Epoch 51/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 104.2073 - val_loss: 62.0543\n",
      "Epoch 52/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 103.8436 - val_loss: 137.0396\n",
      "Epoch 53/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 119.8115 - val_loss: 82.1937\n",
      "Epoch 54/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 122.9731 - val_loss: 43.2573\n",
      "Epoch 55/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 101.0592 - val_loss: 166.4022\n",
      "Epoch 56/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 87.1064 - val_loss: 149.6982\n",
      "Epoch 57/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 97.4677 - val_loss: 7.9429\n",
      "Epoch 58/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 93.2017 - val_loss: 107.2447\n",
      "Epoch 59/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 73.3439 - val_loss: 23.8227\n",
      "Epoch 60/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 66.9294 - val_loss: 74.9878\n",
      "Epoch 61/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 62.6509 - val_loss: 2.9212\n",
      "Epoch 62/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 78.9684 - val_loss: 103.6631\n",
      "Epoch 63/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 65.6740 - val_loss: 5.3137\n",
      "Epoch 64/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 70.2204 - val_loss: 10.5328\n",
      "Epoch 65/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 61.4551 - val_loss: 10.0067\n",
      "Epoch 66/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 76.1958 - val_loss: 2.6732\n",
      "Epoch 67/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 44.1916 - val_loss: 19.7945\n",
      "Epoch 68/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 39.7145 - val_loss: 61.4217\n",
      "Epoch 69/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 55.5736 - val_loss: 1.8205\n",
      "Epoch 70/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 42.2968 - val_loss: 58.2897\n",
      "Epoch 71/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 37.2595 - val_loss: 28.9223\n",
      "Epoch 72/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 31.5644 - val_loss: 11.6731\n",
      "Epoch 73/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 30.7238 - val_loss: 20.5738\n",
      "Epoch 74/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 32.8387 - val_loss: 4.7000\n",
      "Epoch 75/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 22.7950 - val_loss: 7.4586\n",
      "Epoch 76/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 21.8314 - val_loss: 13.9924\n",
      "Epoch 77/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 23.0620 - val_loss: 0.9138\n",
      "Epoch 78/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 19.5142 - val_loss: 1.6292\n",
      "Epoch 79/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 29.0760 - val_loss: 49.1364\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 22.6626 - val_loss: 3.7666\n",
      "Epoch 81/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 16.4797 - val_loss: 1.5447\n",
      "Epoch 82/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 16.9290 - val_loss: 4.0025\n",
      "Epoch 83/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 14.5966 - val_loss: 7.9254\n",
      "Epoch 84/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.0775 - val_loss: 5.5103\n",
      "Epoch 85/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.8407 - val_loss: 12.2846\n",
      "Epoch 86/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 18.6957 - val_loss: 8.6902\n",
      "Epoch 87/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.9356 - val_loss: 1.7637\n",
      "Epoch 88/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.6775 - val_loss: 0.8411\n",
      "Epoch 89/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.6095 - val_loss: 33.0638\n",
      "Epoch 90/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 13.4349 - val_loss: 8.5925\n",
      "Epoch 91/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.2107 - val_loss: 3.3295\n",
      "Epoch 92/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4095 - val_loss: 3.5731\n",
      "Epoch 93/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.2349 - val_loss: 0.1899\n",
      "Epoch 94/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.2326 - val_loss: 3.1518\n",
      "Epoch 95/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.9760 - val_loss: 1.1957\n",
      "Epoch 96/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.3907 - val_loss: 11.2203\n",
      "Epoch 97/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3424 - val_loss: 0.1284\n",
      "Epoch 98/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4566 - val_loss: 2.3534\n",
      "Epoch 99/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7803 - val_loss: 0.2930\n",
      "Epoch 100/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.4585 - val_loss: 5.5288\n",
      "Epoch 101/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.7636 - val_loss: 10.8629\n",
      "Epoch 102/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5662 - val_loss: 8.7812\n",
      "Epoch 103/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.8940 - val_loss: 1.1073\n",
      "Epoch 104/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2221 - val_loss: 1.4772\n",
      "Epoch 105/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6386 - val_loss: 0.0704\n",
      "Epoch 106/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0604 - val_loss: 7.7890\n",
      "Epoch 107/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8480 - val_loss: 0.2552\n",
      "Epoch 108/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3234 - val_loss: 0.0825\n",
      "Epoch 109/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7871 - val_loss: 1.0264\n",
      "Epoch 110/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5713 - val_loss: 2.4515\n",
      "Epoch 111/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8786 - val_loss: 0.0359\n",
      "Epoch 112/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - val_loss: 0.0754\n",
      "Epoch 113/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - val_loss: 1.1462\n",
      "Epoch 114/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - val_loss: 0.0732\n",
      "Epoch 115/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 2.6013\n",
      "Epoch 116/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0001 - val_loss: 1.9247\n",
      "Epoch 117/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 0.1180\n",
      "Epoch 118/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3935 - val_loss: 0.0507\n",
      "Epoch 119/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2732 - val_loss: 0.1675\n",
      "Epoch 120/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1739 - val_loss: 0.2028\n",
      "Epoch 121/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2193 - val_loss: 0.0755\n",
      "Epoch 122/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1159 - val_loss: 0.5455\n",
      "Epoch 123/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3831 - val_loss: 0.0305\n",
      "Epoch 124/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.1851\n",
      "Epoch 125/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2172 - val_loss: 0.0237\n",
      "Epoch 126/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0294\n",
      "Epoch 127/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1350 - val_loss: 0.1123\n",
      "Epoch 128/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.0270\n",
      "Epoch 129/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1037 - val_loss: 0.0196\n",
      "Epoch 130/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1232 - val_loss: 0.0810\n",
      "Epoch 131/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.1554\n",
      "Epoch 132/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0435\n",
      "Epoch 133/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1584 - val_loss: 0.0380\n",
      "Epoch 134/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1717 - val_loss: 0.0339\n",
      "Epoch 135/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0848 - val_loss: 0.2773\n",
      "Epoch 136/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0647 - val_loss: 0.2737\n",
      "Epoch 137/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0840 - val_loss: 0.0249\n",
      "Epoch 138/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0766\n",
      "Epoch 139/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0232\n",
      "Epoch 140/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.6131\n",
      "Epoch 141/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2159 - val_loss: 1.4038\n",
      "Epoch 142/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4117 - val_loss: 0.1608\n",
      "Epoch 143/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1386 - val_loss: 0.2399\n",
      "Epoch 144/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1792 - val_loss: 0.0955\n",
      "Epoch 145/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.1112\n",
      "Epoch 146/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0740\n",
      "Epoch 147/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2005 - val_loss: 0.3210\n",
      "Epoch 148/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2713 - val_loss: 0.4406\n",
      "Epoch 149/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3803 - val_loss: 1.0432\n",
      "Epoch 150/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5683 - val_loss: 0.2415\n",
      "Epoch 151/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1904 - val_loss: 2.7698\n",
      "Epoch 152/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4954 - val_loss: 0.9026\n",
      "Epoch 153/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 12.1417 - val_loss: 0.1728\n",
      "Epoch 154/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 30.1106 - val_loss: 13.0965\n",
      "Epoch 155/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 42.7556 - val_loss: 86.7985\n",
      "Epoch 156/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1757.6970 - val_loss: 3056.8477\n",
      "Epoch 157/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 722.7531 - val_loss: 673.3104\n",
      "Epoch 158/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 248.2489 - val_loss: 391.3235\n",
      "Epoch 159/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 112.4790 - val_loss: 35.6471\n",
      "Epoch 160/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 13.8057 - val_loss: 1.4249\n",
      "Epoch 161/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 9.9924 - val_loss: 27.8171\n",
      "Epoch 162/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.9509 - val_loss: 0.2545\n",
      "Epoch 163/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3856 - val_loss: 0.2993\n",
      "Epoch 164/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2847 - val_loss: 0.1740\n",
      "Epoch 165/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1266 - val_loss: 0.0240\n",
      "Epoch 166/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1390 - val_loss: 0.0223\n",
      "Epoch 167/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0947 - val_loss: 0.2219\n",
      "Epoch 168/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2036 - val_loss: 0.1132\n",
      "Epoch 169/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4059 - val_loss: 0.3138\n",
      "Epoch 170/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - val_loss: 0.5510\n",
      "Epoch 171/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2584 - val_loss: 0.1731\n",
      "Epoch 172/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.1130\n",
      "Epoch 173/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0879 - val_loss: 1.4004\n",
      "Epoch 174/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6086 - val_loss: 3.2845\n",
      "Epoch 175/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.5184 - val_loss: 5.1699\n",
      "Epoch 176/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0829 - val_loss: 0.6760\n",
      "Epoch 177/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5002 - val_loss: 0.0548\n",
      "Epoch 178/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0967\n",
      "Epoch 179/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2613 - val_loss: 2.6027\n",
      "Epoch 180/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9630 - val_loss: 4.0309\n",
      "Epoch 181/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.0383 - val_loss: 1.4138\n",
      "Epoch 182/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4192 - val_loss: 14.2955\n",
      "Epoch 183/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 225.7938 - val_loss: 488.0627\n",
      "Epoch 184/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 346.6715 - val_loss: 1683.9655\n",
      "Epoch 185/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 961.3157 - val_loss: 27.1566\n",
      "Epoch 186/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 99.8225 - val_loss: 27.2918\n",
      "Epoch 187/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 17.6863 - val_loss: 0.2139\n",
      "Epoch 188/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 11.4176 - val_loss: 6.6640\n",
      "Epoch 189/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9354 - val_loss: 1.1653\n",
      "Epoch 190/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7790 - val_loss: 0.6676\n",
      "Epoch 191/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.1233 - val_loss: 20.8147\n",
      "Epoch 192/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.6355 - val_loss: 0.2168\n",
      "Epoch 193/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4769 - val_loss: 1.2658\n",
      "Epoch 194/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2731 - val_loss: 2.1946\n",
      "Epoch 195/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2567 - val_loss: 0.3222\n",
      "Epoch 196/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0877 - val_loss: 1.6435\n",
      "Epoch 197/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8194 - val_loss: 2.7333\n",
      "Epoch 198/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 30.8451 - val_loss: 34.3837\n",
      "Epoch 199/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 315.1909 - val_loss: 341.8645\n",
      "Epoch 200/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 152.0253 - val_loss: 1036.8502\n",
      "Epoch 201/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 423.4121 - val_loss: 611.5564\n",
      "Epoch 202/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 92.4949 - val_loss: 0.8784\n",
      "Epoch 203/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 22.1067 - val_loss: 0.1024\n",
      "Epoch 204/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.1056 - val_loss: 5.6742\n",
      "Epoch 205/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2956 - val_loss: 0.2572\n",
      "Epoch 206/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7016 - val_loss: 1.1164\n",
      "Epoch 207/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 20.0952 - val_loss: 11.5170\n",
      "Epoch 208/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.2558 - val_loss: 14.7792\n",
      "Epoch 209/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 14.2228 - val_loss: 8.6204\n",
      "Epoch 210/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 69.0610 - val_loss: 34.3390\n",
      "Epoch 211/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 225.2566 - val_loss: 3893.4336\n",
      "Epoch 212/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 924.6729 - val_loss: 14.7198\n",
      "Epoch 213/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 91.7008 - val_loss: 23.2526\n",
      "Epoch 214/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 59.8761 - val_loss: 30.1942\n",
      "Epoch 215/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.8285 - val_loss: 0.3619\n",
      "Epoch 216/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9337 - val_loss: 0.4205\n",
      "Epoch 217/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4514 - val_loss: 19.6841\n",
      "Epoch 218/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 25.7103 - val_loss: 0.1355\n",
      "Epoch 219/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.9496 - val_loss: 4.4595\n",
      "Epoch 220/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3717 - val_loss: 1.1801\n",
      "Epoch 221/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3885 - val_loss: 1.9880\n",
      "Epoch 222/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9847 - val_loss: 0.0447\n",
      "Epoch 223/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3020 - val_loss: 0.6493\n",
      "Epoch 224/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5456 - val_loss: 0.5720\n",
      "Epoch 225/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7261 - val_loss: 13.2446\n",
      "Epoch 226/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 128.0407 - val_loss: 1113.8595\n",
      "Epoch 227/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 300.6510 - val_loss: 19.1586\n",
      "Epoch 228/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 64.4900 - val_loss: 16.3400\n",
      "Epoch 229/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.9877 - val_loss: 30.3788\n",
      "Epoch 230/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 18.0531 - val_loss: 1.8586\n",
      "Epoch 231/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10.0063 - val_loss: 0.9015\n",
      "Epoch 232/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0978 - val_loss: 0.2511\n",
      "Epoch 233/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4478 - val_loss: 6.1466\n",
      "Epoch 234/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6414 - val_loss: 0.1766\n",
      "Epoch 235/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.6181 - val_loss: 12.7992\n",
      "Epoch 236/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 328.6201 - val_loss: 14.3845\n",
      "Epoch 237/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 85.9428 - val_loss: 0.3861\n",
      "Epoch 238/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 18.7216 - val_loss: 0.3394\n",
      "Epoch 239/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.2209 - val_loss: 0.0261\n",
      "Epoch 240/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10.5675 - val_loss: 11.4935\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 122.7194 - val_loss: 106.9188\n",
      "Epoch 242/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 29.6474 - val_loss: 1.7310\n",
      "Epoch 243/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 35.0023 - val_loss: 402.2976\n",
      "Epoch 244/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 450.5791 - val_loss: 1144.8965\n",
      "Epoch 245/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 637.3173 - val_loss: 1721.5099\n",
      "Epoch 246/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 550.2671 - val_loss: 1426.3019\n",
      "Epoch 247/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 373.9281 - val_loss: 290.5728\n",
      "Epoch 248/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 146.4951 - val_loss: 202.4313\n",
      "Epoch 249/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 46.6480 - val_loss: 2.0537\n",
      "Epoch 250/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.1373 - val_loss: 1.2130\n",
      "Epoch 251/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - val_loss: 0.1044\n",
      "Epoch 252/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3290 - val_loss: 0.9209\n",
      "Epoch 253/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7318 - val_loss: 0.6862\n",
      "Epoch 254/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3126 - val_loss: 0.0270\n",
      "Epoch 255/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2276 - val_loss: 0.2480\n",
      "Epoch 256/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1986 - val_loss: 0.0419\n",
      "Epoch 257/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5298 - val_loss: 0.0761\n",
      "Epoch 258/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1282 - val_loss: 0.1248\n",
      "Epoch 259/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1914 - val_loss: 0.3632\n",
      "Epoch 260/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5046 - val_loss: 0.0334\n",
      "Epoch 261/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0959 - val_loss: 0.0782\n",
      "Epoch 262/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1403 - val_loss: 0.0550\n",
      "Epoch 263/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.0443\n",
      "Epoch 264/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2258 - val_loss: 2.2592\n",
      "Epoch 265/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.1916 - val_loss: 0.8372\n",
      "Epoch 266/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4454 - val_loss: 6.6481\n",
      "Epoch 267/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 31.4423 - val_loss: 94.8941\n",
      "Epoch 268/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 97.5462 - val_loss: 709.8875\n",
      "Epoch 269/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2774.0044 - val_loss: 6170.8105\n",
      "Epoch 270/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1355.3774 - val_loss: 88.4031\n",
      "Epoch 271/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 152.3897 - val_loss: 137.3912\n",
      "Epoch 272/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 39.2444 - val_loss: 0.4551\n",
      "Epoch 273/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.5553 - val_loss: 12.9545\n",
      "Epoch 274/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.0037 - val_loss: 1.9078\n",
      "Epoch 275/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9495 - val_loss: 1.0533\n",
      "Epoch 276/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9232 - val_loss: 0.1621\n",
      "Epoch 277/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3687 - val_loss: 0.6743\n",
      "Epoch 278/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3727 - val_loss: 0.1052\n",
      "Epoch 279/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3344 - val_loss: 0.2074\n",
      "Epoch 280/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3531 - val_loss: 0.3384\n",
      "Epoch 281/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2461 - val_loss: 0.0373\n",
      "Epoch 282/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1843 - val_loss: 0.0929\n",
      "Epoch 283/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1477 - val_loss: 0.1255\n",
      "Epoch 284/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3841 - val_loss: 1.1649\n",
      "Epoch 285/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4864 - val_loss: 0.3726\n",
      "Epoch 286/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1887 - val_loss: 0.0966\n",
      "Epoch 287/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.2994\n",
      "Epoch 288/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2104 - val_loss: 0.0231\n",
      "Epoch 289/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0372\n",
      "Epoch 290/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1300 - val_loss: 0.0591\n",
      "Epoch 291/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1036 - val_loss: 0.1321\n",
      "Epoch 292/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.2220\n",
      "Epoch 293/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2670 - val_loss: 0.1232\n",
      "Epoch 294/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3396 - val_loss: 0.9126\n",
      "Epoch 295/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2887 - val_loss: 0.6733\n",
      "Epoch 296/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3715 - val_loss: 0.7398\n",
      "Epoch 297/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1618 - val_loss: 0.0731\n",
      "Epoch 298/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.0671\n",
      "Epoch 299/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0997 - val_loss: 0.1898\n",
      "Epoch 300/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6936 - val_loss: 1.4508\n",
      "Epoch 301/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.9965 - val_loss: 10.8974\n",
      "Epoch 302/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.9773 - val_loss: 0.2164\n",
      "Epoch 303/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1737 - val_loss: 1.4625\n",
      "Epoch 304/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2315 - val_loss: 0.0197\n",
      "Epoch 305/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2088 - val_loss: 0.3685\n",
      "Epoch 306/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1317 - val_loss: 0.1037\n",
      "Epoch 307/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5282 - val_loss: 4.3164\n",
      "Epoch 308/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5949 - val_loss: 0.4118\n",
      "Epoch 309/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7696 - val_loss: 11.0206\n",
      "Epoch 310/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 18.7812 - val_loss: 11.4510\n",
      "Epoch 311/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.9845 - val_loss: 25.8853\n",
      "Epoch 312/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 75.1715 - val_loss: 33.7530\n",
      "Epoch 313/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 54.0895 - val_loss: 81.2154\n",
      "Epoch 314/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 177.7841 - val_loss: 1008.0404\n",
      "Epoch 315/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1175.1732 - val_loss: 1.5299\n",
      "Epoch 316/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 73.2902 - val_loss: 114.8692\n",
      "Epoch 317/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 67.5759 - val_loss: 233.5445\n",
      "Epoch 318/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 37.0502 - val_loss: 7.0810\n",
      "Epoch 319/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2672 - val_loss: 1.6599\n",
      "Epoch 320/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2791 - val_loss: 0.5872\n",
      "Epoch 321/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3689 - val_loss: 0.9360\n",
      "Epoch 322/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3463 - val_loss: 6.5219\n",
      "Epoch 323/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.5049 - val_loss: 14.1625\n",
      "Epoch 324/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.5454 - val_loss: 0.1506\n",
      "Epoch 325/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 71.3212 - val_loss: 332.4391\n",
      "Epoch 326/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 106.0284 - val_loss: 248.5735\n",
      "Epoch 327/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 52.0417 - val_loss: 0.5209\n",
      "Epoch 328/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 74.6838 - val_loss: 574.7790\n",
      "Epoch 329/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 199.6213 - val_loss: 854.9733\n",
      "Epoch 330/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 405.0538 - val_loss: 82.7001\n",
      "Epoch 331/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 29.6674 - val_loss: 36.6320\n",
      "Epoch 332/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 57.4725 - val_loss: 80.3743\n",
      "Epoch 333/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 137.4807 - val_loss: 34.6239\n",
      "Epoch 334/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 26.2010 - val_loss: 41.1838\n",
      "Epoch 335/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 21.9795 - val_loss: 7.0817\n",
      "Epoch 336/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.8295 - val_loss: 2.8309\n",
      "Epoch 337/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.8270 - val_loss: 4.3415\n",
      "Epoch 338/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4142 - val_loss: 2.4868\n",
      "Epoch 339/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 26.4680 - val_loss: 8.4898\n",
      "Epoch 340/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.5524 - val_loss: 4.1240\n",
      "Epoch 341/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.0351 - val_loss: 21.2789\n",
      "Epoch 342/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 25.4392 - val_loss: 51.1154\n",
      "Epoch 343/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 16.3411 - val_loss: 14.7961\n",
      "Epoch 344/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 17.0587 - val_loss: 14.3791\n",
      "Epoch 345/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 201.6647 - val_loss: 1320.1760\n",
      "Epoch 346/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 844.2531 - val_loss: 23.5678\n",
      "Epoch 347/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 123.9583 - val_loss: 30.3783\n",
      "Epoch 348/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 32.1129 - val_loss: 24.5665\n",
      "Epoch 349/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7220 - val_loss: 1.5351\n",
      "Epoch 350/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6416 - val_loss: 0.2490\n",
      "Epoch 351/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1455 - val_loss: 0.4251\n",
      "Epoch 352/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2570 - val_loss: 0.2827\n",
      "Epoch 353/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2625 - val_loss: 0.4852\n",
      "Epoch 354/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2106 - val_loss: 0.2358\n",
      "Epoch 355/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8305 - val_loss: 0.2783\n",
      "Epoch 356/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1561 - val_loss: 0.1004\n",
      "Epoch 357/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1312 - val_loss: 0.6134\n",
      "Epoch 358/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - val_loss: 0.3490\n",
      "Epoch 359/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2282 - val_loss: 1.8193\n",
      "Epoch 360/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 21.7765 - val_loss: 215.4449\n",
      "Epoch 361/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 70.3165 - val_loss: 57.9906\n",
      "Epoch 362/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 64.4499 - val_loss: 83.4796\n",
      "Epoch 363/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 12.6643 - val_loss: 2.3234\n",
      "Epoch 364/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 12.2867 - val_loss: 16.6481\n",
      "Epoch 365/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9706 - val_loss: 12.1130\n",
      "Epoch 366/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 70.7209 - val_loss: 1505.6606\n",
      "Epoch 367/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 531.3981 - val_loss: 2513.9321\n",
      "Epoch 368/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2203.0999 - val_loss: 0.1390\n",
      "Epoch 369/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 417.3700 - val_loss: 4.3210\n",
      "Epoch 370/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 74.7271 - val_loss: 35.9364\n",
      "Epoch 371/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 63.1615 - val_loss: 117.5372\n",
      "Epoch 372/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 61.3510 - val_loss: 8.2057\n",
      "Epoch 373/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.4185 - val_loss: 0.7374\n",
      "Epoch 374/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9098 - val_loss: 0.9887\n",
      "Epoch 375/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0539 - val_loss: 0.0553\n",
      "Epoch 376/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - val_loss: 1.5240\n",
      "Epoch 377/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5325 - val_loss: 0.2287\n",
      "Epoch 378/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8896 - val_loss: 0.7087\n",
      "Epoch 379/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5587 - val_loss: 3.7096\n",
      "Epoch 380/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3797 - val_loss: 1.3381\n",
      "Epoch 381/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5882 - val_loss: 0.1233\n",
      "Epoch 382/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2512 - val_loss: 0.5600\n",
      "Epoch 383/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5493 - val_loss: 1.2141\n",
      "Epoch 384/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.1432 - val_loss: 4.8338\n",
      "Epoch 385/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5098 - val_loss: 1.1217\n",
      "Epoch 386/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3041 - val_loss: 0.0717\n",
      "Epoch 387/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.0305\n",
      "Epoch 388/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6861 - val_loss: 0.4159\n",
      "Epoch 389/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0271 - val_loss: 1.4839\n",
      "Epoch 390/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3307 - val_loss: 0.1081\n",
      "Epoch 391/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2390 - val_loss: 0.7614\n",
      "Epoch 392/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.9597\n",
      "Epoch 393/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3398 - val_loss: 0.0355\n",
      "Epoch 394/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1349 - val_loss: 0.0235\n",
      "Epoch 395/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2284 - val_loss: 0.7982\n",
      "Epoch 396/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2556 - val_loss: 0.0217\n",
      "Epoch 397/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1473 - val_loss: 0.2527\n",
      "Epoch 398/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5767 - val_loss: 0.3105\n",
      "Epoch 399/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2241 - val_loss: 0.0190\n",
      "Epoch 400/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.3889 - val_loss: 1.9568\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2218 - val_loss: 1.9123\n",
      "Epoch 402/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8240 - val_loss: 0.7770\n",
      "Epoch 403/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.5862 - val_loss: 20.4750\n",
      "Epoch 404/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 14.3812 - val_loss: 281.5556\n",
      "Epoch 405/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 264.2206 - val_loss: 263.0809\n",
      "Epoch 406/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 219.2149 - val_loss: 388.8555\n",
      "Epoch 407/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 792.5182 - val_loss: 1485.2358\n",
      "Epoch 408/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 383.2723 - val_loss: 124.3024\n",
      "Epoch 409/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 100.8603 - val_loss: 103.5518\n",
      "Epoch 410/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 36.2817 - val_loss: 34.0561\n",
      "Epoch 411/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 31.7455 - val_loss: 76.7964\n",
      "Epoch 412/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 13.7324 - val_loss: 10.1818\n",
      "Epoch 413/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.9553 - val_loss: 0.3870\n",
      "Epoch 414/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.4934 - val_loss: 2.6597\n",
      "Epoch 415/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7422 - val_loss: 0.4106\n",
      "Epoch 416/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2638 - val_loss: 0.0256\n",
      "Epoch 417/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1577 - val_loss: 0.1064\n",
      "Epoch 418/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3110 - val_loss: 0.1629\n",
      "Epoch 419/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9372 - val_loss: 0.8110\n",
      "Epoch 420/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - val_loss: 0.5029\n",
      "Epoch 421/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2088 - val_loss: 0.0708\n",
      "Epoch 422/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2644 - val_loss: 1.8084\n",
      "Epoch 423/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2285 - val_loss: 0.0320\n",
      "Epoch 424/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - val_loss: 0.3671\n",
      "Epoch 425/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6190 - val_loss: 1.0375\n",
      "Epoch 426/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8638 - val_loss: 0.0364\n",
      "Epoch 427/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.2653 - val_loss: 13.6073\n",
      "Epoch 428/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.3042 - val_loss: 15.5801\n",
      "Epoch 429/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.7485 - val_loss: 3.8377\n",
      "Epoch 430/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.8769 - val_loss: 9.7971\n",
      "Epoch 431/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 44.0713 - val_loss: 20.9800\n",
      "Epoch 432/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 774.5441 - val_loss: 3705.0454\n",
      "Epoch 433/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1102.4458 - val_loss: 2885.5706\n",
      "Epoch 434/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1132.9581 - val_loss: 416.9958\n",
      "Epoch 435/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 48.4095 - val_loss: 12.1183\n",
      "Epoch 436/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.2013 - val_loss: 4.1176\n",
      "Epoch 437/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.6944 - val_loss: 10.1817\n",
      "Epoch 438/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.0696 - val_loss: 37.2009\n",
      "Epoch 439/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.1621 - val_loss: 4.7532\n",
      "Epoch 440/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0932 - val_loss: 0.0771\n",
      "Epoch 441/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - val_loss: 0.2936\n",
      "Epoch 442/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 1.4353\n",
      "Epoch 443/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9263 - val_loss: 0.2110\n",
      "Epoch 444/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2895 - val_loss: 0.0666\n",
      "Epoch 445/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2222 - val_loss: 0.0648\n",
      "Epoch 446/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.0871\n",
      "Epoch 447/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1396\n",
      "Epoch 448/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2083 - val_loss: 0.0554\n",
      "Epoch 449/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1644 - val_loss: 0.5163\n",
      "Epoch 450/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1280 - val_loss: 0.0408\n",
      "Epoch 451/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1015 - val_loss: 0.0418\n",
      "Epoch 452/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1845 - val_loss: 0.1722\n",
      "Epoch 453/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.2461\n",
      "Epoch 454/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1758 - val_loss: 0.1542\n",
      "Epoch 455/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1255 - val_loss: 0.2521\n",
      "Epoch 456/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3413 - val_loss: 0.2081\n",
      "Epoch 457/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1808 - val_loss: 0.2185\n",
      "Epoch 458/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.1447\n",
      "Epoch 459/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0974 - val_loss: 0.0207\n",
      "Epoch 460/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0923 - val_loss: 0.2448\n",
      "Epoch 461/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0970 - val_loss: 0.0318\n",
      "Epoch 462/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1213 - val_loss: 0.0944\n",
      "Epoch 463/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1519 - val_loss: 0.5018\n",
      "Epoch 464/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7406 - val_loss: 0.0315\n",
      "Epoch 465/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7006 - val_loss: 0.0800\n",
      "Epoch 466/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1378 - val_loss: 0.2781\n",
      "Epoch 467/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2459 - val_loss: 0.0606\n",
      "Epoch 468/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0786 - val_loss: 0.0225\n",
      "Epoch 469/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - val_loss: 1.7017\n",
      "Epoch 470/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2825 - val_loss: 0.0701\n",
      "Epoch 471/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - val_loss: 12.9913\n",
      "Epoch 472/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 103.1534 - val_loss: 1812.1892\n",
      "Epoch 473/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1148.3502 - val_loss: 368.7679\n",
      "Epoch 474/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 164.1640 - val_loss: 303.7632\n",
      "Epoch 475/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 49.9226 - val_loss: 11.5947\n",
      "Epoch 476/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.7038 - val_loss: 8.2396\n",
      "Epoch 477/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5101 - val_loss: 3.0189\n",
      "Epoch 478/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4194 - val_loss: 4.9191\n",
      "Epoch 479/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1827 - val_loss: 0.6820\n",
      "Epoch 480/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7048 - val_loss: 0.0382\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2241 - val_loss: 1.4493\n",
      "Epoch 482/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9185 - val_loss: 0.1688\n",
      "Epoch 483/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7868 - val_loss: 1.8937\n",
      "Epoch 484/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3900 - val_loss: 0.0601\n",
      "Epoch 485/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1907 - val_loss: 0.4102\n",
      "Epoch 486/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2586 - val_loss: 0.0548\n",
      "Epoch 487/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2224 - val_loss: 0.0204\n",
      "Epoch 488/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1786 - val_loss: 0.2737\n",
      "Epoch 489/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5153 - val_loss: 0.1074\n",
      "Epoch 490/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 11.4438 - val_loss: 0.0188\n",
      "Epoch 491/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 14.5831 - val_loss: 49.0995\n",
      "Epoch 492/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.5826 - val_loss: 0.0986\n",
      "Epoch 493/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7047 - val_loss: 3.7962\n",
      "Epoch 494/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 12.9289 - val_loss: 12.6732\n",
      "Epoch 495/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.6214 - val_loss: 88.7448\n",
      "Epoch 496/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 73.2463 - val_loss: 11.9773\n",
      "Epoch 497/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 21.4561 - val_loss: 4.3515\n",
      "Epoch 498/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 363.1770 - val_loss: 20.3133\n",
      "Epoch 499/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 30.8045 - val_loss: 0.7454\n",
      "Epoch 500/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2764 - val_loss: 0.0382\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(X, y, epochs=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "Y3o42inpzaZH"
   },
   "outputs": [],
   "source": [
    "test = pd.read_excel(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JfgABdtz-eP",
    "outputId": "73ea3be4-b68d-48be-ddd2-84487e8e5410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152 entries, 0 to 151\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    152 non-null    datetime64[ns]\n",
      " 1   Price   152 non-null    float64       \n",
      " 2   Open    152 non-null    float64       \n",
      " 3   High    152 non-null    float64       \n",
      " 4   Low     152 non-null    float64       \n",
      " 5   Volume  152 non-null    object        \n",
      " 6   Chg%    152 non-null    float64       \n",
      " 7   Nifty   152 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(6), object(1)\n",
      "memory usage: 9.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "QX5WxYgaw129",
    "outputId": "a8f8848d-0507-4bcb-c967-699243af832a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Chg%</th>\n",
       "      <th>Nifty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>152.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.451039</td>\n",
       "      <td>81.445921</td>\n",
       "      <td>81.674849</td>\n",
       "      <td>81.277237</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>17816.147697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.241872</td>\n",
       "      <td>1.247907</td>\n",
       "      <td>1.246959</td>\n",
       "      <td>1.254997</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>474.313079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>78.587000</td>\n",
       "      <td>78.627000</td>\n",
       "      <td>79.002000</td>\n",
       "      <td>78.393000</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>16483.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>79.945500</td>\n",
       "      <td>79.957250</td>\n",
       "      <td>80.058500</td>\n",
       "      <td>79.772750</td>\n",
       "      <td>-0.001700</td>\n",
       "      <td>17529.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>81.638500</td>\n",
       "      <td>81.671500</td>\n",
       "      <td>81.927000</td>\n",
       "      <td>81.529500</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>17838.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.590500</td>\n",
       "      <td>82.603250</td>\n",
       "      <td>82.791000</td>\n",
       "      <td>82.404750</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>18123.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.013000</td>\n",
       "      <td>82.991000</td>\n",
       "      <td>83.268000</td>\n",
       "      <td>82.776000</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>18812.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Price        Open        High         Low        Chg%  \\\n",
       "count  152.000000  152.000000  152.000000  152.000000  152.000000   \n",
       "mean    81.451039   81.445921   81.674849   81.277237    0.000316   \n",
       "std      1.241872    1.247907    1.246959    1.254997    0.003350   \n",
       "min     78.587000   78.627000   79.002000   78.393000   -0.009300   \n",
       "25%     79.945500   79.957250   80.058500   79.772750   -0.001700   \n",
       "50%     81.638500   81.671500   81.927000   81.529500    0.000150   \n",
       "75%     82.590500   82.603250   82.791000   82.404750    0.001925   \n",
       "max     83.013000   82.991000   83.268000   82.776000    0.014300   \n",
       "\n",
       "              Nifty  \n",
       "count    152.000000  \n",
       "mean   17816.147697  \n",
       "std      474.313079  \n",
       "min    16483.850000  \n",
       "25%    17529.412500  \n",
       "50%    17838.975000  \n",
       "75%    18123.712500  \n",
       "max    18812.500000  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "WwcqePatw7-Q"
   },
   "outputs": [],
   "source": [
    "test_feature = [\"Open\", \"High\", \"Low\", \"Nifty\"]\n",
    "x_test = test[test_feature] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rz1v9quExDRu",
    "outputId": "41d030ed-651b-4c5b-94e3-472a658eb110"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Nifty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.425</td>\n",
       "      <td>82.628</td>\n",
       "      <td>82.355</td>\n",
       "      <td>17321.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.588</td>\n",
       "      <td>82.634</td>\n",
       "      <td>82.365</td>\n",
       "      <td>17450.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.690</td>\n",
       "      <td>82.761</td>\n",
       "      <td>82.554</td>\n",
       "      <td>17303.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.871</td>\n",
       "      <td>82.951</td>\n",
       "      <td>82.627</td>\n",
       "      <td>17392.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.643</td>\n",
       "      <td>83.026</td>\n",
       "      <td>82.628</td>\n",
       "      <td>17465.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High     Low     Nifty\n",
       "0  82.425  82.628  82.355  17321.90\n",
       "1  82.588  82.634  82.365  17450.90\n",
       "2  82.690  82.761  82.554  17303.95\n",
       "3  82.871  82.951  82.627  17392.70\n",
       "4  82.643  83.026  82.628  17465.80"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f82EkrxUxHYs",
    "outputId": "1272feb2-6ccf-4a9d-9550-2d3abbf47a87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    82.350\n",
       "1    82.430\n",
       "2    82.640\n",
       "3    82.642\n",
       "4    82.897\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Price\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "TvXYjjbTxIge"
   },
   "outputs": [],
   "source": [
    "y = test[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMM0G2gXxLYu",
    "outputId": "57867fb7-9d1d-4cd7-beaf-fc77e75f037c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0594\n",
      "Test Loss: 0.059377238154411316\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "test_loss = model.evaluate(x_test, y)\n",
    "print('Test Loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O85r08FY7YOc",
    "outputId": "1e1b4cf5-ebbd-4d81-d076-5e6ca842f3cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[82.2162  ],\n",
       "       [82.26448 ],\n",
       "       [82.38643 ],\n",
       "       [82.55476 ],\n",
       "       [82.54756 ],\n",
       "       [82.46413 ],\n",
       "       [82.56966 ],\n",
       "       [82.502396],\n",
       "       [82.42287 ],\n",
       "       [82.50209 ],\n",
       "       [82.47566 ],\n",
       "       [82.60542 ],\n",
       "       [82.55629 ],\n",
       "       [82.398026],\n",
       "       [82.26723 ],\n",
       "       [82.32918 ],\n",
       "       [82.40547 ],\n",
       "       [82.51204 ],\n",
       "       [82.34694 ],\n",
       "       [81.87453 ],\n",
       "       [81.74324 ],\n",
       "       [81.62331 ],\n",
       "       [81.587845],\n",
       "       [81.355545],\n",
       "       [81.32051 ],\n",
       "       [81.41194 ],\n",
       "       [81.377396],\n",
       "       [81.010635],\n",
       "       [80.98842 ],\n",
       "       [81.150406],\n",
       "       [81.417984],\n",
       "       [81.51796 ],\n",
       "       [81.261856],\n",
       "       [81.09285 ],\n",
       "       [81.35005 ],\n",
       "       [81.44966 ],\n",
       "       [81.88191 ],\n",
       "       [82.05818 ],\n",
       "       [82.35719 ],\n",
       "       [82.43135 ],\n",
       "       [82.54518 ],\n",
       "       [82.600174],\n",
       "       [82.43947 ],\n",
       "       [82.47682 ],\n",
       "       [82.57045 ],\n",
       "       [82.58174 ],\n",
       "       [82.51662 ],\n",
       "       [82.49489 ],\n",
       "       [82.56166 ],\n",
       "       [82.59627 ],\n",
       "       [82.54567 ],\n",
       "       [82.4756  ],\n",
       "       [82.49147 ],\n",
       "       [82.554825],\n",
       "       [82.50575 ],\n",
       "       [82.36806 ],\n",
       "       [82.494095],\n",
       "       [82.341324],\n",
       "       [82.106155],\n",
       "       [82.12373 ],\n",
       "       [82.32619 ],\n",
       "       [82.08003 ],\n",
       "       [81.392166],\n",
       "       [81.130264],\n",
       "       [81.004715],\n",
       "       [81.34633 ],\n",
       "       [81.424515],\n",
       "       [81.532   ],\n",
       "       [81.42903 ],\n",
       "       [81.45778 ],\n",
       "       [81.567276],\n",
       "       [81.500015],\n",
       "       [81.5403  ],\n",
       "       [81.42714 ],\n",
       "       [81.42873 ],\n",
       "       [81.13637 ],\n",
       "       [80.97279 ],\n",
       "       [80.742874],\n",
       "       [80.572464],\n",
       "       [81.33284 ],\n",
       "       [81.2303  ],\n",
       "       [81.903885],\n",
       "       [82.31203 ],\n",
       "       [82.62135 ],\n",
       "       [82.45619 ],\n",
       "       [82.47615 ],\n",
       "       [82.37123 ],\n",
       "       [82.14162 ],\n",
       "       [82.05446 ],\n",
       "       [82.44978 ],\n",
       "       [82.45686 ],\n",
       "       [82.628555],\n",
       "       [82.75728 ],\n",
       "       [82.46376 ],\n",
       "       [81.97554 ],\n",
       "       [82.05324 ],\n",
       "       [82.01643 ],\n",
       "       [82.14284 ],\n",
       "       [81.990005],\n",
       "       [82.09035 ],\n",
       "       [82.31416 ],\n",
       "       [82.263626],\n",
       "       [81.68318 ],\n",
       "       [81.27791 ],\n",
       "       [81.44643 ],\n",
       "       [81.273575],\n",
       "       [81.47725 ],\n",
       "       [81.55562 ],\n",
       "       [81.29549 ],\n",
       "       [81.25453 ],\n",
       "       [80.86067 ],\n",
       "       [80.508804],\n",
       "       [79.70949 ],\n",
       "       [79.49495 ],\n",
       "       [79.52388 ],\n",
       "       [79.58113 ],\n",
       "       [79.472305],\n",
       "       [79.35713 ],\n",
       "       [79.25929 ],\n",
       "       [79.41255 ],\n",
       "       [79.41585 ],\n",
       "       [79.53133 ],\n",
       "       [79.655594],\n",
       "       [79.62038 ],\n",
       "       [79.65846 ],\n",
       "       [79.57234 ],\n",
       "       [79.37898 ],\n",
       "       [79.652664],\n",
       "       [79.80354 ],\n",
       "       [79.67061 ],\n",
       "       [79.67177 ],\n",
       "       [79.61922 ],\n",
       "       [79.62752 ],\n",
       "       [79.651566],\n",
       "       [79.62776 ],\n",
       "       [79.393265],\n",
       "       [79.15608 ],\n",
       "       [79.30946 ],\n",
       "       [79.46266 ],\n",
       "       [79.21297 ],\n",
       "       [79.268875],\n",
       "       [79.34517 ],\n",
       "       [79.08449 ],\n",
       "       [79.29109 ],\n",
       "       [78.758865],\n",
       "       [78.66658 ],\n",
       "       [78.937515],\n",
       "       [79.28346 ],\n",
       "       [79.524734],\n",
       "       [79.63887 ],\n",
       "       [79.534744],\n",
       "       [79.55049 ]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygJqfrft8rqW",
    "outputId": "bc4a4b1a-2e7d-445b-97e4-04c75fa7025a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      82.350\n",
       "1      82.430\n",
       "2      82.640\n",
       "3      82.642\n",
       "4      82.897\n",
       "        ...  \n",
       "147    79.336\n",
       "148    79.626\n",
       "149    79.845\n",
       "150    79.843\n",
       "151    79.691\n",
       "Name: Price, Length: 152, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[82.55525]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[82.871, 82.952, 82.627, 17392.70]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
