{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UjYnSTfyE2R",
    "outputId": "0259412e-0fac-4349-d899-f2f9a51fe58c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-fE4YFqbyolK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8Xyf-WEjywMo"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FWUYxMXny2Lj",
    "outputId": "347ec32c-91d2-4456-88f7-f5e2d46d0f19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Chg%</th>\n",
       "      <th>NIFTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01-Jan-20</td>\n",
       "      <td>71.227</td>\n",
       "      <td>71.365</td>\n",
       "      <td>71.377</td>\n",
       "      <td>71.225</td>\n",
       "      <td>1.16K</td>\n",
       "      <td>-0.18%</td>\n",
       "      <td>12182.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>02-Jan-20</td>\n",
       "      <td>71.350</td>\n",
       "      <td>71.235</td>\n",
       "      <td>71.408</td>\n",
       "      <td>71.235</td>\n",
       "      <td>4.63K</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>12282.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>03-Jan-20</td>\n",
       "      <td>71.770</td>\n",
       "      <td>71.610</td>\n",
       "      <td>71.844</td>\n",
       "      <td>71.520</td>\n",
       "      <td>7.49K</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>12226.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>06-Jan-20</td>\n",
       "      <td>71.867</td>\n",
       "      <td>72.011</td>\n",
       "      <td>72.123</td>\n",
       "      <td>71.834</td>\n",
       "      <td>7.44K</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>11993.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>07-Jan-20</td>\n",
       "      <td>71.845</td>\n",
       "      <td>71.765</td>\n",
       "      <td>71.923</td>\n",
       "      <td>71.670</td>\n",
       "      <td>6.69K</td>\n",
       "      <td>-0.03%</td>\n",
       "      <td>12052.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       Date   Price    Open    High     Low Volume    Chg%     NIFTY\n",
       "0      1  01-Jan-20  71.227  71.365  71.377  71.225  1.16K  -0.18%  12182.50\n",
       "1      2  02-Jan-20  71.350  71.235  71.408  71.235  4.63K   0.17%  12282.20\n",
       "2      3  03-Jan-20  71.770  71.610  71.844  71.520  7.49K   0.59%  12226.65\n",
       "3      4  06-Jan-20  71.867  72.011  72.123  71.834  7.44K   0.14%  11993.05\n",
       "4      5  07-Jan-20  71.845  71.765  71.923  71.670  6.69K  -0.03%  12052.95"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "7DJliEMZjvKL",
    "outputId": "f90156cd-fadf-422c-d056-260c1598b0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 696 entries, 0 to 695\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   index   696 non-null    int64  \n",
      " 1   Date    696 non-null    object \n",
      " 2   Price   696 non-null    float64\n",
      " 3   Open    696 non-null    float64\n",
      " 4   High    696 non-null    float64\n",
      " 5   Low     696 non-null    float64\n",
      " 6   Volume  696 non-null    object \n",
      " 7   Chg%    696 non-null    object \n",
      " 8   NIFTY   696 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(3)\n",
      "memory usage: 49.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "-6rB0VMciy_9",
    "outputId": "5c68ae24-8261-4c1b-e31e-b623c3e3b738"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Chg%</th>\n",
       "      <th>NIFTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01-Jan-20</td>\n",
       "      <td>71.227</td>\n",
       "      <td>71.365</td>\n",
       "      <td>71.377</td>\n",
       "      <td>71.225</td>\n",
       "      <td>1.16K</td>\n",
       "      <td>-0.18%</td>\n",
       "      <td>12182.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>02-Jan-20</td>\n",
       "      <td>71.350</td>\n",
       "      <td>71.235</td>\n",
       "      <td>71.408</td>\n",
       "      <td>71.235</td>\n",
       "      <td>4.63K</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>12282.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>03-Jan-20</td>\n",
       "      <td>71.770</td>\n",
       "      <td>71.610</td>\n",
       "      <td>71.844</td>\n",
       "      <td>71.520</td>\n",
       "      <td>7.49K</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>12226.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>06-Jan-20</td>\n",
       "      <td>71.867</td>\n",
       "      <td>72.011</td>\n",
       "      <td>72.123</td>\n",
       "      <td>71.834</td>\n",
       "      <td>7.44K</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>11993.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>07-Jan-20</td>\n",
       "      <td>71.845</td>\n",
       "      <td>71.765</td>\n",
       "      <td>71.923</td>\n",
       "      <td>71.670</td>\n",
       "      <td>6.69K</td>\n",
       "      <td>-0.03%</td>\n",
       "      <td>12052.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>692</td>\n",
       "      <td>25-Aug-22</td>\n",
       "      <td>79.862</td>\n",
       "      <td>79.811</td>\n",
       "      <td>80.006</td>\n",
       "      <td>79.749</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10%</td>\n",
       "      <td>16983.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>693</td>\n",
       "      <td>26-Aug-22</td>\n",
       "      <td>79.961</td>\n",
       "      <td>79.883</td>\n",
       "      <td>79.983</td>\n",
       "      <td>79.709</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>17123.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>694</td>\n",
       "      <td>29-Aug-22</td>\n",
       "      <td>79.954</td>\n",
       "      <td>79.989</td>\n",
       "      <td>80.135</td>\n",
       "      <td>79.892</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01%</td>\n",
       "      <td>17014.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>695</td>\n",
       "      <td>30-Aug-22</td>\n",
       "      <td>79.665</td>\n",
       "      <td>79.968</td>\n",
       "      <td>79.985</td>\n",
       "      <td>79.417</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.36%</td>\n",
       "      <td>17185.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>696</td>\n",
       "      <td>31-Aug-22</td>\n",
       "      <td>79.491</td>\n",
       "      <td>79.707</td>\n",
       "      <td>79.717</td>\n",
       "      <td>79.415</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.22%</td>\n",
       "      <td>17311.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>696 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       Date   Price    Open    High     Low Volume    Chg%     NIFTY\n",
       "0        1  01-Jan-20  71.227  71.365  71.377  71.225  1.16K  -0.18%  12182.50\n",
       "1        2  02-Jan-20  71.350  71.235  71.408  71.235  4.63K   0.17%  12282.20\n",
       "2        3  03-Jan-20  71.770  71.610  71.844  71.520  7.49K   0.59%  12226.65\n",
       "3        4  06-Jan-20  71.867  72.011  72.123  71.834  7.44K   0.14%  11993.05\n",
       "4        5  07-Jan-20  71.845  71.765  71.923  71.670  6.69K  -0.03%  12052.95\n",
       "..     ...        ...     ...     ...     ...     ...    ...     ...       ...\n",
       "691    692  25-Aug-22  79.862  79.811  80.006  79.749      0   0.10%  16983.55\n",
       "692    693  26-Aug-22  79.961  79.883  79.983  79.709      0   0.12%  17123.60\n",
       "693    694  29-Aug-22  79.954  79.989  80.135  79.892      0  -0.01%  17014.35\n",
       "694    695  30-Aug-22  79.665  79.968  79.985  79.417      0  -0.36%  17185.70\n",
       "695    696  31-Aug-22  79.491  79.707  79.717  79.415      0  -0.22%  17311.80\n",
       "\n",
       "[696 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgwW0OiqkHmZ",
    "outputId": "cbe922a0-e7d5-45df-af34-7305cf778de7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>NIFTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>696.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>696.000000</td>\n",
       "      <td>696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>348.500000</td>\n",
       "      <td>74.774272</td>\n",
       "      <td>74.775737</td>\n",
       "      <td>74.953815</td>\n",
       "      <td>74.612264</td>\n",
       "      <td>14534.659052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>201.062179</td>\n",
       "      <td>1.944422</td>\n",
       "      <td>1.937994</td>\n",
       "      <td>1.952544</td>\n",
       "      <td>1.936294</td>\n",
       "      <td>2839.842186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.710000</td>\n",
       "      <td>70.720000</td>\n",
       "      <td>70.945000</td>\n",
       "      <td>70.682000</td>\n",
       "      <td>7610.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>174.750000</td>\n",
       "      <td>73.466250</td>\n",
       "      <td>73.498500</td>\n",
       "      <td>73.618000</td>\n",
       "      <td>73.293500</td>\n",
       "      <td>11933.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>348.500000</td>\n",
       "      <td>74.520500</td>\n",
       "      <td>74.544000</td>\n",
       "      <td>74.650000</td>\n",
       "      <td>74.340000</td>\n",
       "      <td>15307.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>522.250000</td>\n",
       "      <td>75.694000</td>\n",
       "      <td>75.705000</td>\n",
       "      <td>75.945750</td>\n",
       "      <td>75.492500</td>\n",
       "      <td>17119.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>696.000000</td>\n",
       "      <td>79.990000</td>\n",
       "      <td>80.026000</td>\n",
       "      <td>80.235000</td>\n",
       "      <td>79.892000</td>\n",
       "      <td>18477.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index       Price        Open        High         Low  \\\n",
       "count  696.000000  696.000000  696.000000  696.000000  696.000000   \n",
       "mean   348.500000   74.774272   74.775737   74.953815   74.612264   \n",
       "std    201.062179    1.944422    1.937994    1.952544    1.936294   \n",
       "min      1.000000   70.710000   70.720000   70.945000   70.682000   \n",
       "25%    174.750000   73.466250   73.498500   73.618000   73.293500   \n",
       "50%    348.500000   74.520500   74.544000   74.650000   74.340000   \n",
       "75%    522.250000   75.694000   75.705000   75.945750   75.492500   \n",
       "max    696.000000   79.990000   80.026000   80.235000   79.892000   \n",
       "\n",
       "              NIFTY  \n",
       "count    696.000000  \n",
       "mean   14534.659052  \n",
       "std     2839.842186  \n",
       "min     7610.250000  \n",
       "25%    11933.612500  \n",
       "50%    15307.450000  \n",
       "75%    17119.100000  \n",
       "max    18477.050000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UAS7x2tHy3uo"
   },
   "outputs": [],
   "source": [
    "features = [\"Open\",\"High\",\"Low\",\"NIFTY\"]\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "kfauplWoy-lx",
    "outputId": "ad6fc692-3614-40f6-aa8d-7a0112e8249a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>NIFTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.365</td>\n",
       "      <td>71.377</td>\n",
       "      <td>71.225</td>\n",
       "      <td>12182.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.235</td>\n",
       "      <td>71.408</td>\n",
       "      <td>71.235</td>\n",
       "      <td>12282.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.610</td>\n",
       "      <td>71.844</td>\n",
       "      <td>71.520</td>\n",
       "      <td>12226.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.011</td>\n",
       "      <td>72.123</td>\n",
       "      <td>71.834</td>\n",
       "      <td>11993.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.765</td>\n",
       "      <td>71.923</td>\n",
       "      <td>71.670</td>\n",
       "      <td>12052.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open    High     Low     NIFTY\n",
       "0  71.365  71.377  71.225  12182.50\n",
       "1  71.235  71.408  71.235  12282.20\n",
       "2  71.610  71.844  71.520  12226.65\n",
       "3  72.011  72.123  71.834  11993.05\n",
       "4  71.765  71.923  71.670  12052.95"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2PEnMGZzCf0",
    "outputId": "71024039-1a4a-46e9-9089-c533159e1ab2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uNo52isBh_-A"
   },
   "outputs": [],
   "source": [
    "# X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KaydZ-MliD9M"
   },
   "outputs": [],
   "source": [
    "# X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Sgu-1H-BiGNs"
   },
   "outputs": [],
   "source": [
    "# my_tensor2 = tf.convert_to_tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WO9ryEA0zGk_"
   },
   "outputs": [],
   "source": [
    "y = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ht7qyBHud0fD"
   },
   "outputs": [],
   "source": [
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3LMBCVaAdkY8"
   },
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s20Zg-a7hYk-",
    "outputId": "49942b18-7efc-4916-f524-194d4afb560a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Woogqft2eABE",
    "outputId": "89d2155c-0d79-428d-da7b-bc061ebda9fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (696, 4)\n",
      "y shape: (696, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ETOhIUUozPUe"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eqiWMmKWzS6Z"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HRHRwbzmzXIp"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZtIIMxPzY_Q",
    "outputId": "e9e9e829-5380-479f-b4cc-94aacdfedd8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 547926.5625 - val_loss: 221765.1094\n",
      "Epoch 2/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 44708.9336 - val_loss: 22101.0410\n",
      "Epoch 3/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6317.7446 - val_loss: 16.0503\n",
      "Epoch 4/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1376.6245 - val_loss: 471.5923\n",
      "Epoch 5/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 543.4747 - val_loss: 507.7740\n",
      "Epoch 6/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 264.7780 - val_loss: 109.4403\n",
      "Epoch 7/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 237.8724 - val_loss: 83.6245\n",
      "Epoch 8/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 231.6848 - val_loss: 73.5424\n",
      "Epoch 9/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 233.2151 - val_loss: 102.8387\n",
      "Epoch 10/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 230.5230 - val_loss: 93.2449\n",
      "Epoch 11/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 230.2491 - val_loss: 75.5729\n",
      "Epoch 12/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 232.3360 - val_loss: 118.2718\n",
      "Epoch 13/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 233.4564 - val_loss: 100.2382\n",
      "Epoch 14/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 240.4440 - val_loss: 56.9755\n",
      "Epoch 15/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 235.2106 - val_loss: 81.9784\n",
      "Epoch 16/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 229.2587 - val_loss: 113.2589\n",
      "Epoch 17/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 231.1834 - val_loss: 116.2821\n",
      "Epoch 18/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 231.6449 - val_loss: 178.3772\n",
      "Epoch 19/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 231.1626 - val_loss: 83.6233\n",
      "Epoch 20/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 229.7748 - val_loss: 25.0296\n",
      "Epoch 21/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 226.9357 - val_loss: 78.1716\n",
      "Epoch 22/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 222.7313 - val_loss: 77.3248\n",
      "Epoch 23/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 225.2856 - val_loss: 117.9078\n",
      "Epoch 24/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 222.1807 - val_loss: 68.5442\n",
      "Epoch 25/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 221.2227 - val_loss: 24.4547\n",
      "Epoch 26/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 222.5282 - val_loss: 76.5064\n",
      "Epoch 27/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 221.8749 - val_loss: 29.1789\n",
      "Epoch 28/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 229.2640 - val_loss: 67.7215\n",
      "Epoch 29/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 231.2545 - val_loss: 168.3422\n",
      "Epoch 30/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 216.5049 - val_loss: 133.6482\n",
      "Epoch 31/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 221.5978 - val_loss: 43.9224\n",
      "Epoch 32/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 216.8723 - val_loss: 110.5776\n",
      "Epoch 33/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 218.2511 - val_loss: 121.2519\n",
      "Epoch 34/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 215.2400 - val_loss: 33.3671\n",
      "Epoch 35/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 219.8367 - val_loss: 70.0405\n",
      "Epoch 36/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 210.2859 - val_loss: 41.7390\n",
      "Epoch 37/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 210.3974 - val_loss: 31.2309\n",
      "Epoch 38/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 211.6146 - val_loss: 47.7197\n",
      "Epoch 39/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 214.6238 - val_loss: 207.4156\n",
      "Epoch 40/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 215.4049 - val_loss: 81.3090\n",
      "Epoch 41/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 216.2247 - val_loss: 13.1814\n",
      "Epoch 42/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 228.3212 - val_loss: 86.4457\n",
      "Epoch 43/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 204.1565 - val_loss: 56.8569\n",
      "Epoch 44/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 208.5054 - val_loss: 229.1141\n",
      "Epoch 45/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 218.1929 - val_loss: 14.1509\n",
      "Epoch 46/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 220.6702 - val_loss: 181.2082\n",
      "Epoch 47/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 226.4695 - val_loss: 10.3229\n",
      "Epoch 48/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 203.4606 - val_loss: 120.0799\n",
      "Epoch 49/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 203.7398 - val_loss: 54.6422\n",
      "Epoch 50/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 205.1008 - val_loss: 95.8111\n",
      "Epoch 51/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 193.5548 - val_loss: 44.6276\n",
      "Epoch 52/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 194.9303 - val_loss: 91.6007\n",
      "Epoch 53/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 201.2054 - val_loss: 21.0909\n",
      "Epoch 54/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 199.9243 - val_loss: 105.6317\n",
      "Epoch 55/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 194.4480 - val_loss: 18.3981\n",
      "Epoch 56/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 190.0175 - val_loss: 63.3985\n",
      "Epoch 57/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 186.5990 - val_loss: 111.3111\n",
      "Epoch 58/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 191.8322 - val_loss: 30.7911\n",
      "Epoch 59/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 188.6143 - val_loss: 65.4284\n",
      "Epoch 60/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 182.7843 - val_loss: 30.6063\n",
      "Epoch 61/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 186.8240 - val_loss: 17.5013\n",
      "Epoch 62/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 182.8793 - val_loss: 113.2653\n",
      "Epoch 63/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 181.3880 - val_loss: 17.9537\n",
      "Epoch 64/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 180.3075 - val_loss: 27.0573\n",
      "Epoch 65/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 177.3916 - val_loss: 126.1025\n",
      "Epoch 66/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 199.3655 - val_loss: 8.5846\n",
      "Epoch 67/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 192.9115 - val_loss: 17.3667\n",
      "Epoch 68/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 173.2112 - val_loss: 9.8000\n",
      "Epoch 69/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 174.5922 - val_loss: 16.6749\n",
      "Epoch 70/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 173.4059 - val_loss: 22.4194\n",
      "Epoch 71/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 169.5215 - val_loss: 117.0102\n",
      "Epoch 72/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 165.0240 - val_loss: 39.2110\n",
      "Epoch 73/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 168.3566 - val_loss: 72.2616\n",
      "Epoch 74/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 162.7354 - val_loss: 37.6165\n",
      "Epoch 75/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 161.4607 - val_loss: 147.7101\n",
      "Epoch 76/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 169.2782 - val_loss: 6.9233\n",
      "Epoch 77/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 173.3771 - val_loss: 48.2750\n",
      "Epoch 78/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 160.2799 - val_loss: 26.7295\n",
      "Epoch 79/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 160.9851 - val_loss: 6.7068\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 175.1493 - val_loss: 19.2862\n",
      "Epoch 81/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 163.5205 - val_loss: 67.9120\n",
      "Epoch 82/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 157.3059 - val_loss: 44.2284\n",
      "Epoch 83/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 151.9650 - val_loss: 38.8549\n",
      "Epoch 84/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 151.4714 - val_loss: 105.5922\n",
      "Epoch 85/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 164.8954 - val_loss: 180.3954\n",
      "Epoch 86/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 166.7530 - val_loss: 122.5503\n",
      "Epoch 87/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 149.8637 - val_loss: 116.5204\n",
      "Epoch 88/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 151.8997 - val_loss: 79.7166\n",
      "Epoch 89/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 141.4516 - val_loss: 38.4013\n",
      "Epoch 90/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 141.5093 - val_loss: 34.0617\n",
      "Epoch 91/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 138.2943 - val_loss: 22.0080\n",
      "Epoch 92/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 146.7393 - val_loss: 23.8615\n",
      "Epoch 93/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 146.2013 - val_loss: 40.8750\n",
      "Epoch 94/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 136.9228 - val_loss: 84.2161\n",
      "Epoch 95/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 130.9348 - val_loss: 16.3156\n",
      "Epoch 96/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 133.0082 - val_loss: 59.5013\n",
      "Epoch 97/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 132.5314 - val_loss: 22.2611\n",
      "Epoch 98/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 127.2848 - val_loss: 98.6452\n",
      "Epoch 99/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 127.7947 - val_loss: 27.8767\n",
      "Epoch 100/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 124.2132 - val_loss: 58.5007\n",
      "Epoch 101/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 122.6619 - val_loss: 6.6588\n",
      "Epoch 102/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 125.3121 - val_loss: 9.0361\n",
      "Epoch 103/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 136.4379 - val_loss: 14.4499\n",
      "Epoch 104/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 121.2729 - val_loss: 25.6449\n",
      "Epoch 105/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 115.7826 - val_loss: 137.9642\n",
      "Epoch 106/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 118.1630 - val_loss: 43.9351\n",
      "Epoch 107/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 124.2589 - val_loss: 58.8448\n",
      "Epoch 108/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 113.5398 - val_loss: 30.5245\n",
      "Epoch 109/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 118.1556 - val_loss: 16.1536\n",
      "Epoch 110/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 115.5599 - val_loss: 17.7407\n",
      "Epoch 111/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 112.3160 - val_loss: 5.1929\n",
      "Epoch 112/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 111.3439 - val_loss: 24.1280\n",
      "Epoch 113/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 106.6586 - val_loss: 43.6741\n",
      "Epoch 114/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 102.6354 - val_loss: 188.3227\n",
      "Epoch 115/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 112.2745 - val_loss: 78.3011\n",
      "Epoch 116/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 99.6684 - val_loss: 25.1381\n",
      "Epoch 117/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 101.0949 - val_loss: 70.1019\n",
      "Epoch 118/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 100.5779 - val_loss: 26.8214\n",
      "Epoch 119/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 100.9487 - val_loss: 56.4829\n",
      "Epoch 120/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 101.3580 - val_loss: 49.3124\n",
      "Epoch 121/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 92.1479 - val_loss: 64.7271\n",
      "Epoch 122/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 94.3193 - val_loss: 51.0004\n",
      "Epoch 123/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 92.0962 - val_loss: 88.3075\n",
      "Epoch 124/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 87.6979 - val_loss: 17.2863\n",
      "Epoch 125/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 88.7696 - val_loss: 24.7576\n",
      "Epoch 126/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 84.7405 - val_loss: 18.7542\n",
      "Epoch 127/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 82.6889 - val_loss: 28.9256\n",
      "Epoch 128/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 85.0500 - val_loss: 12.6214\n",
      "Epoch 129/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 80.3767 - val_loss: 10.3426\n",
      "Epoch 130/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 81.6516 - val_loss: 58.7727\n",
      "Epoch 131/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 78.1905 - val_loss: 41.9582\n",
      "Epoch 132/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 77.0710 - val_loss: 26.1775\n",
      "Epoch 133/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 77.8253 - val_loss: 43.5811\n",
      "Epoch 134/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 78.3045 - val_loss: 24.0894\n",
      "Epoch 135/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 86.7455 - val_loss: 22.9744\n",
      "Epoch 136/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 72.8489 - val_loss: 35.1267\n",
      "Epoch 137/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 68.6327 - val_loss: 73.7878\n",
      "Epoch 138/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 69.5588 - val_loss: 24.0256\n",
      "Epoch 139/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 66.0632 - val_loss: 11.6630\n",
      "Epoch 140/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 69.4619 - val_loss: 44.3577\n",
      "Epoch 141/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 69.6427 - val_loss: 76.7387\n",
      "Epoch 142/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 74.9544 - val_loss: 3.2042\n",
      "Epoch 143/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 61.5994 - val_loss: 28.7478\n",
      "Epoch 144/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 62.3696 - val_loss: 15.8062\n",
      "Epoch 145/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 57.8744 - val_loss: 22.3013\n",
      "Epoch 146/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 56.9376 - val_loss: 16.1126\n",
      "Epoch 147/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 56.2672 - val_loss: 6.6733\n",
      "Epoch 148/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 56.5168 - val_loss: 35.8089\n",
      "Epoch 149/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 54.6620 - val_loss: 2.3827\n",
      "Epoch 150/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 63.2590 - val_loss: 2.8574\n",
      "Epoch 151/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 62.5741 - val_loss: 101.6180\n",
      "Epoch 152/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 79.3315 - val_loss: 35.2019\n",
      "Epoch 153/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 66.3553 - val_loss: 60.4041\n",
      "Epoch 154/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 67.8974 - val_loss: 14.7340\n",
      "Epoch 155/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 52.8105 - val_loss: 10.1950\n",
      "Epoch 156/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 51.0097 - val_loss: 72.8445\n",
      "Epoch 157/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 59.9376 - val_loss: 2.5696\n",
      "Epoch 158/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 52.1288 - val_loss: 2.3751\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 51.8447 - val_loss: 12.3045\n",
      "Epoch 160/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 50.6689 - val_loss: 57.0914\n",
      "Epoch 161/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 47.5695 - val_loss: 7.9136\n",
      "Epoch 162/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 51.8333 - val_loss: 1.8434\n",
      "Epoch 163/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 39.6802 - val_loss: 6.0609\n",
      "Epoch 164/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 37.4990 - val_loss: 7.1068\n",
      "Epoch 165/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 36.5761 - val_loss: 2.7940\n",
      "Epoch 166/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 51.6669 - val_loss: 30.5381\n",
      "Epoch 167/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 36.2871 - val_loss: 16.6074\n",
      "Epoch 168/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 34.2360 - val_loss: 18.1137\n",
      "Epoch 169/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 29.1003 - val_loss: 1.4324\n",
      "Epoch 170/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 30.3383 - val_loss: 10.7158\n",
      "Epoch 171/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 29.0906 - val_loss: 1.1772\n",
      "Epoch 172/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 28.1215 - val_loss: 19.6145\n",
      "Epoch 173/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 25.8420 - val_loss: 1.2206\n",
      "Epoch 174/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 27.6525 - val_loss: 9.4098\n",
      "Epoch 175/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 33.7380 - val_loss: 1.2393\n",
      "Epoch 176/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 24.2307 - val_loss: 3.8767\n",
      "Epoch 177/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 22.7797 - val_loss: 1.0829\n",
      "Epoch 178/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 28.6909 - val_loss: 1.5271\n",
      "Epoch 179/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 25.3875 - val_loss: 3.9510\n",
      "Epoch 180/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 22.6580 - val_loss: 1.9969\n",
      "Epoch 181/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 18.8516 - val_loss: 7.3229\n",
      "Epoch 182/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 19.5748 - val_loss: 2.9601\n",
      "Epoch 183/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 18.7313 - val_loss: 1.8767\n",
      "Epoch 184/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 22.4511 - val_loss: 24.7780\n",
      "Epoch 185/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 17.0924 - val_loss: 17.2295\n",
      "Epoch 186/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 16.7958 - val_loss: 11.6313\n",
      "Epoch 187/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 16.2884 - val_loss: 30.2027\n",
      "Epoch 188/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 16.7272 - val_loss: 23.0262\n",
      "Epoch 189/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 14.8247 - val_loss: 4.4292\n",
      "Epoch 190/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 15.5862 - val_loss: 5.7509\n",
      "Epoch 191/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 12.4818 - val_loss: 3.5636\n",
      "Epoch 192/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 13.5572 - val_loss: 1.5273\n",
      "Epoch 193/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 16.3166 - val_loss: 1.3216\n",
      "Epoch 194/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 12.1909 - val_loss: 1.0645\n",
      "Epoch 195/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.4035 - val_loss: 0.7666\n",
      "Epoch 196/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.8887 - val_loss: 8.5188\n",
      "Epoch 197/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.6392 - val_loss: 4.7157\n",
      "Epoch 198/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.6742 - val_loss: 0.6311\n",
      "Epoch 199/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.7185 - val_loss: 0.8552\n",
      "Epoch 200/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 11.1453 - val_loss: 15.8060\n",
      "Epoch 201/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10.8092 - val_loss: 0.5924\n",
      "Epoch 202/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.0909 - val_loss: 1.5332\n",
      "Epoch 203/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.7910 - val_loss: 8.9717\n",
      "Epoch 204/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9467 - val_loss: 0.3445\n",
      "Epoch 205/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3515 - val_loss: 9.1839\n",
      "Epoch 206/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3783 - val_loss: 0.8266\n",
      "Epoch 207/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.8264 - val_loss: 1.5151\n",
      "Epoch 208/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.1769 - val_loss: 6.6536\n",
      "Epoch 209/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.6171 - val_loss: 0.2038\n",
      "Epoch 210/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2059 - val_loss: 0.2135\n",
      "Epoch 211/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5942 - val_loss: 3.2778\n",
      "Epoch 212/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.9909 - val_loss: 11.2183\n",
      "Epoch 213/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.0757 - val_loss: 0.2150\n",
      "Epoch 214/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 3.5103 - val_loss: 0.8796\n",
      "Epoch 215/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.0330 - val_loss: 0.1436\n",
      "Epoch 216/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.8286 - val_loss: 0.4727\n",
      "Epoch 217/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.7420 - val_loss: 0.1320\n",
      "Epoch 218/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.7135 - val_loss: 2.8459\n",
      "Epoch 219/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.8005 - val_loss: 0.5552\n",
      "Epoch 220/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.9801 - val_loss: 0.2645\n",
      "Epoch 221/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3842 - val_loss: 2.9840\n",
      "Epoch 222/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.1047 - val_loss: 1.7696\n",
      "Epoch 223/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2189 - val_loss: 0.5227\n",
      "Epoch 224/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7026 - val_loss: 0.2739\n",
      "Epoch 225/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6086 - val_loss: 0.2485\n",
      "Epoch 226/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6183 - val_loss: 0.0795\n",
      "Epoch 227/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6823 - val_loss: 0.1126\n",
      "Epoch 228/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.3092 - val_loss: 0.4237\n",
      "Epoch 229/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1259 - val_loss: 2.2874\n",
      "Epoch 230/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.1863 - val_loss: 2.6284\n",
      "Epoch 231/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.2623 - val_loss: 3.4639\n",
      "Epoch 232/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6551 - val_loss: 0.4374\n",
      "Epoch 233/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0714 - val_loss: 0.5150\n",
      "Epoch 234/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7289 - val_loss: 0.3342\n",
      "Epoch 235/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6822 - val_loss: 0.5239\n",
      "Epoch 236/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7260 - val_loss: 0.1055\n",
      "Epoch 237/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5544 - val_loss: 1.4261\n",
      "Epoch 238/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7573 - val_loss: 0.3116\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9191 - val_loss: 0.3598\n",
      "Epoch 240/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9151 - val_loss: 0.6839\n",
      "Epoch 241/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3963 - val_loss: 1.1183\n",
      "Epoch 242/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9354 - val_loss: 0.1548\n",
      "Epoch 243/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8976 - val_loss: 3.8089\n",
      "Epoch 244/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2322 - val_loss: 3.4958\n",
      "Epoch 245/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1682 - val_loss: 1.0704\n",
      "Epoch 246/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3435 - val_loss: 0.0383\n",
      "Epoch 247/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2792 - val_loss: 0.0329\n",
      "Epoch 248/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2364 - val_loss: 0.1490\n",
      "Epoch 249/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2459 - val_loss: 0.3317\n",
      "Epoch 250/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1838 - val_loss: 0.0999\n",
      "Epoch 251/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1652 - val_loss: 0.4356\n",
      "Epoch 252/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1921 - val_loss: 0.1166\n",
      "Epoch 253/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1650 - val_loss: 0.9336\n",
      "Epoch 254/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2391 - val_loss: 0.0249\n",
      "Epoch 255/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2067 - val_loss: 0.0561\n",
      "Epoch 256/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2297 - val_loss: 0.2003\n",
      "Epoch 257/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2034 - val_loss: 0.0233\n",
      "Epoch 258/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1009 - val_loss: 0.0248\n",
      "Epoch 259/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1434 - val_loss: 0.1422\n",
      "Epoch 260/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1507 - val_loss: 0.0341\n",
      "Epoch 261/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.0262\n",
      "Epoch 262/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.1120\n",
      "Epoch 263/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1247 - val_loss: 0.4285\n",
      "Epoch 264/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.0227\n",
      "Epoch 265/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.1134\n",
      "Epoch 266/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0332\n",
      "Epoch 267/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1447 - val_loss: 0.3035\n",
      "Epoch 268/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1020 - val_loss: 0.0651\n",
      "Epoch 269/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.6348\n",
      "Epoch 270/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2164 - val_loss: 0.0338\n",
      "Epoch 271/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1023 - val_loss: 0.0553\n",
      "Epoch 272/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0437\n",
      "Epoch 273/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.0418\n",
      "Epoch 274/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0432\n",
      "Epoch 275/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0623\n",
      "Epoch 276/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0627\n",
      "Epoch 277/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0598\n",
      "Epoch 278/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0422\n",
      "Epoch 279/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.1538\n",
      "Epoch 280/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.1462\n",
      "Epoch 281/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1728 - val_loss: 0.0211\n",
      "Epoch 282/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1027 - val_loss: 0.2133\n",
      "Epoch 283/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0855 - val_loss: 0.0245\n",
      "Epoch 284/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0697\n",
      "Epoch 285/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.1703\n",
      "Epoch 286/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1001 - val_loss: 0.0588\n",
      "Epoch 287/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0603\n",
      "Epoch 288/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0399\n",
      "Epoch 289/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.1413\n",
      "Epoch 290/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.6287\n",
      "Epoch 291/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1378 - val_loss: 0.1053\n",
      "Epoch 292/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0587 - val_loss: 0.0558\n",
      "Epoch 293/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0964 - val_loss: 0.1650\n",
      "Epoch 294/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.3511\n",
      "Epoch 295/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0942\n",
      "Epoch 296/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.1239\n",
      "Epoch 297/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0263\n",
      "Epoch 298/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0324\n",
      "Epoch 299/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1438 - val_loss: 0.0977\n",
      "Epoch 300/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0897\n",
      "Epoch 301/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.1953\n",
      "Epoch 302/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1107 - val_loss: 0.0229\n",
      "Epoch 303/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0495\n",
      "Epoch 304/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0245\n",
      "Epoch 305/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0496\n",
      "Epoch 306/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0357\n",
      "Epoch 307/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1780 - val_loss: 0.0327\n",
      "Epoch 308/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3573 - val_loss: 0.2855\n",
      "Epoch 309/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4048 - val_loss: 0.0934\n",
      "Epoch 310/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 0.5992\n",
      "Epoch 311/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8201 - val_loss: 0.4889\n",
      "Epoch 312/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2376 - val_loss: 0.2036\n",
      "Epoch 313/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3352 - val_loss: 0.2172\n",
      "Epoch 314/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5331 - val_loss: 0.5024\n",
      "Epoch 315/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3218 - val_loss: 0.0648\n",
      "Epoch 316/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3691 - val_loss: 0.0528\n",
      "Epoch 317/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7435 - val_loss: 0.0836\n",
      "Epoch 318/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 2.0741\n",
      "Epoch 319/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8917 - val_loss: 8.0878\n",
      "Epoch 320/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 53.6329 - val_loss: 32.0941\n",
      "Epoch 321/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 244.8596 - val_loss: 3032.2891\n",
      "Epoch 322/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 910.5938 - val_loss: 1065.5439\n",
      "Epoch 323/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 248.7930 - val_loss: 170.5471\n",
      "Epoch 324/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 33.1550 - val_loss: 0.4805\n",
      "Epoch 325/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7164 - val_loss: 2.5725\n",
      "Epoch 326/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3577 - val_loss: 0.8319\n",
      "Epoch 327/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3566 - val_loss: 1.7638\n",
      "Epoch 328/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9108 - val_loss: 0.0495\n",
      "Epoch 329/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3393 - val_loss: 0.1438\n",
      "Epoch 330/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2781 - val_loss: 1.1560\n",
      "Epoch 331/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5233 - val_loss: 0.9413\n",
      "Epoch 332/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3588 - val_loss: 0.2266\n",
      "Epoch 333/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5433 - val_loss: 1.6136\n",
      "Epoch 334/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.1692 - val_loss: 1.4742\n",
      "Epoch 335/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2803 - val_loss: 0.0383\n",
      "Epoch 336/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1446 - val_loss: 0.2912\n",
      "Epoch 337/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1487 - val_loss: 0.0225\n",
      "Epoch 338/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.1212\n",
      "Epoch 339/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.9439\n",
      "Epoch 340/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2907 - val_loss: 0.0630\n",
      "Epoch 341/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2597 - val_loss: 0.5430\n",
      "Epoch 342/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1466 - val_loss: 0.3972\n",
      "Epoch 343/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4011 - val_loss: 0.0802\n",
      "Epoch 344/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - val_loss: 0.0226\n",
      "Epoch 345/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1033 - val_loss: 0.0803\n",
      "Epoch 346/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.1809\n",
      "Epoch 347/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1392 - val_loss: 0.3027\n",
      "Epoch 348/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - val_loss: 0.2933\n",
      "Epoch 349/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4825 - val_loss: 3.8991\n",
      "Epoch 350/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.9988 - val_loss: 19.1321\n",
      "Epoch 351/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.6284 - val_loss: 3.0072\n",
      "Epoch 352/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.0904 - val_loss: 6.3651\n",
      "Epoch 353/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 52.2861 - val_loss: 3.7236\n",
      "Epoch 354/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 58.5965 - val_loss: 66.9327\n",
      "Epoch 355/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 184.7797 - val_loss: 275.2088\n",
      "Epoch 356/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 68.2810 - val_loss: 39.7183\n",
      "Epoch 357/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 17.1899 - val_loss: 40.2344\n",
      "Epoch 358/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.3870 - val_loss: 0.1729\n",
      "Epoch 359/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5489 - val_loss: 8.8676\n",
      "Epoch 360/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.6189 - val_loss: 15.0014\n",
      "Epoch 361/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.8932 - val_loss: 7.2856\n",
      "Epoch 362/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.0414 - val_loss: 0.3836\n",
      "Epoch 363/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.7644 - val_loss: 0.1077\n",
      "Epoch 364/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2624 - val_loss: 0.2076\n",
      "Epoch 365/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1002 - val_loss: 0.1393\n",
      "Epoch 366/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2260 - val_loss: 0.1003\n",
      "Epoch 367/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3917 - val_loss: 0.3167\n",
      "Epoch 368/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6295 - val_loss: 2.2945\n",
      "Epoch 369/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.3435 - val_loss: 0.0408\n",
      "Epoch 370/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.0070 - val_loss: 1.2448\n",
      "Epoch 371/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 219.2698 - val_loss: 57.4831\n",
      "Epoch 372/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 567.7679 - val_loss: 394.1958\n",
      "Epoch 373/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 95.1755 - val_loss: 113.1347\n",
      "Epoch 374/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 20.4731 - val_loss: 48.3774\n",
      "Epoch 375/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 22.0482 - val_loss: 0.1556\n",
      "Epoch 376/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.9939 - val_loss: 0.0270\n",
      "Epoch 377/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3949 - val_loss: 0.1302\n",
      "Epoch 378/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - val_loss: 2.5264\n",
      "Epoch 379/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8912 - val_loss: 0.8342\n",
      "Epoch 380/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9478 - val_loss: 6.2532\n",
      "Epoch 381/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.8760 - val_loss: 0.5298\n",
      "Epoch 382/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2483 - val_loss: 0.3157\n",
      "Epoch 383/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5261 - val_loss: 0.1426\n",
      "Epoch 384/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - val_loss: 0.8608\n",
      "Epoch 385/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8592 - val_loss: 1.1374\n",
      "Epoch 386/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4425\n",
      "Epoch 387/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1639 - val_loss: 0.0374\n",
      "Epoch 388/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1958 - val_loss: 0.9220\n",
      "Epoch 389/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2741 - val_loss: 0.1888\n",
      "Epoch 390/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.1728 - val_loss: 31.6879\n",
      "Epoch 391/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.9123 - val_loss: 3.6295\n",
      "Epoch 392/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.4360 - val_loss: 11.9659\n",
      "Epoch 393/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 26.7606 - val_loss: 37.9966\n",
      "Epoch 394/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 57.4185 - val_loss: 4.4740\n",
      "Epoch 395/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 32.6164 - val_loss: 35.3944\n",
      "Epoch 396/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 19.9745 - val_loss: 9.4742\n",
      "Epoch 397/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.6392 - val_loss: 3.3982\n",
      "Epoch 398/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.2024 - val_loss: 0.2019\n",
      "Epoch 399/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.2771 - val_loss: 17.8016\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 12.1492 - val_loss: 4.8412\n",
      "Epoch 401/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 13.0566 - val_loss: 8.9256\n",
      "Epoch 402/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 65.5617 - val_loss: 24.3203\n",
      "Epoch 403/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 78.0506 - val_loss: 1425.6250\n",
      "Epoch 404/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1473.4487 - val_loss: 1134.4784\n",
      "Epoch 405/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 535.3843 - val_loss: 276.1551\n",
      "Epoch 406/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 53.2765 - val_loss: 126.3428\n",
      "Epoch 407/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 35.4067 - val_loss: 5.3108\n",
      "Epoch 408/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10.2860 - val_loss: 0.0291\n",
      "Epoch 409/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.0876 - val_loss: 0.0295\n",
      "Epoch 410/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9926 - val_loss: 0.2703\n",
      "Epoch 411/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2466 - val_loss: 0.0375\n",
      "Epoch 412/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2765 - val_loss: 0.0397\n",
      "Epoch 413/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2083 - val_loss: 0.0457\n",
      "Epoch 414/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1648 - val_loss: 0.1884\n",
      "Epoch 415/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.0842\n",
      "Epoch 416/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1757 - val_loss: 0.0351\n",
      "Epoch 417/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1807 - val_loss: 0.0779\n",
      "Epoch 418/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1008 - val_loss: 0.1187\n",
      "Epoch 419/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.1683\n",
      "Epoch 420/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2109 - val_loss: 0.0729\n",
      "Epoch 421/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1152 - val_loss: 0.0219\n",
      "Epoch 422/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0278\n",
      "Epoch 423/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0821\n",
      "Epoch 424/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0445\n",
      "Epoch 425/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0361\n",
      "Epoch 426/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0722\n",
      "Epoch 427/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0764 - val_loss: 0.1283\n",
      "Epoch 428/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1245 - val_loss: 0.0843\n",
      "Epoch 429/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.1600\n",
      "Epoch 430/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2166 - val_loss: 0.5172\n",
      "Epoch 431/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3299 - val_loss: 0.4002\n",
      "Epoch 432/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1011 - val_loss: 0.1602\n",
      "Epoch 433/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1611 - val_loss: 0.1476\n",
      "Epoch 434/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0222\n",
      "Epoch 435/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.5086\n",
      "Epoch 436/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2138 - val_loss: 0.0214\n",
      "Epoch 437/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.1700\n",
      "Epoch 438/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0994 - val_loss: 0.1702\n",
      "Epoch 439/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.2300\n",
      "Epoch 440/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1558 - val_loss: 0.0304\n",
      "Epoch 441/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0913 - val_loss: 0.0279\n",
      "Epoch 442/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.0218\n",
      "Epoch 443/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.1571\n",
      "Epoch 444/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3412 - val_loss: 0.0720\n",
      "Epoch 445/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7357 - val_loss: 3.7380\n",
      "Epoch 446/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0173 - val_loss: 0.0212\n",
      "Epoch 447/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0209\n",
      "Epoch 448/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1140 - val_loss: 0.4790\n",
      "Epoch 449/500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1216 - val_loss: 0.1644\n",
      "Epoch 450/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1021 - val_loss: 0.0221\n",
      "Epoch 451/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2563 - val_loss: 0.0663\n",
      "Epoch 452/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3146 - val_loss: 0.4020\n",
      "Epoch 453/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.9015 - val_loss: 0.1661\n",
      "Epoch 454/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 14.8772 - val_loss: 217.2427\n",
      "Epoch 455/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 112.3360 - val_loss: 547.8756\n",
      "Epoch 456/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 86.5930 - val_loss: 117.3802\n",
      "Epoch 457/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 28.4975 - val_loss: 44.8315\n",
      "Epoch 458/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 19.1115 - val_loss: 2.3331\n",
      "Epoch 459/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.8782 - val_loss: 5.9705\n",
      "Epoch 460/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6800 - val_loss: 9.3609\n",
      "Epoch 461/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.1291 - val_loss: 0.1661\n",
      "Epoch 462/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.8427 - val_loss: 8.4008\n",
      "Epoch 463/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 12.5178 - val_loss: 64.8997\n",
      "Epoch 464/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.6231 - val_loss: 0.8913\n",
      "Epoch 465/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 96.2560 - val_loss: 42.7276\n",
      "Epoch 466/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 122.1936 - val_loss: 110.4509\n",
      "Epoch 467/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 106.4880 - val_loss: 115.8249\n",
      "Epoch 468/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 54.6856 - val_loss: 37.8385\n",
      "Epoch 469/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3478 - val_loss: 2.0426\n",
      "Epoch 470/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8875 - val_loss: 1.3953\n",
      "Epoch 471/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.4753 - val_loss: 0.9592\n",
      "Epoch 472/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4086 - val_loss: 0.6533\n",
      "Epoch 473/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3986 - val_loss: 0.8428\n",
      "Epoch 474/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5066 - val_loss: 0.5595\n",
      "Epoch 475/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1970 - val_loss: 0.0289\n",
      "Epoch 476/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2696 - val_loss: 0.5601\n",
      "Epoch 477/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - val_loss: 0.1032\n",
      "Epoch 478/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4022 - val_loss: 0.5734\n",
      "Epoch 479/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 65.8132 - val_loss: 225.1593\n",
      "Epoch 480/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 147.6065 - val_loss: 138.0665\n",
      "Epoch 481/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 222.4122 - val_loss: 104.0825\n",
      "Epoch 482/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 71.5670 - val_loss: 100.3934\n",
      "Epoch 483/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 23.6741 - val_loss: 16.3155\n",
      "Epoch 484/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 11.2509 - val_loss: 8.9015\n",
      "Epoch 485/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.2754 - val_loss: 0.2903\n",
      "Epoch 486/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10.2778 - val_loss: 43.7203\n",
      "Epoch 487/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 24.1874 - val_loss: 37.6125\n",
      "Epoch 488/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 13.1816 - val_loss: 12.3171\n",
      "Epoch 489/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.6236 - val_loss: 0.0415\n",
      "Epoch 490/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2874 - val_loss: 2.1126\n",
      "Epoch 491/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9449 - val_loss: 1.1743\n",
      "Epoch 492/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8490 - val_loss: 0.2691\n",
      "Epoch 493/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1687 - val_loss: 1.3380\n",
      "Epoch 494/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - val_loss: 0.0771\n",
      "Epoch 495/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4064 - val_loss: 5.0237\n",
      "Epoch 496/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.5625 - val_loss: 0.6735\n",
      "Epoch 497/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 32.5723 - val_loss: 714.4976\n",
      "Epoch 498/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 119.0351 - val_loss: 5.8685\n",
      "Epoch 499/500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 17.5595 - val_loss: 12.6811\n",
      "Epoch 500/500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.6698 - val_loss: 7.2666\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(X, y, epochs=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Y3o42inpzaZH"
   },
   "outputs": [],
   "source": [
    "test = pd.read_excel(\"/content/drive/MyDrive/Data_Detectors_Colabs/Currancy_test_new.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JfgABdtz-eP",
    "outputId": "73ea3be4-b68d-48be-ddd2-84487e8e5410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152 entries, 0 to 151\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    152 non-null    datetime64[ns]\n",
      " 1   Price   152 non-null    float64       \n",
      " 2   Open    152 non-null    float64       \n",
      " 3   High    152 non-null    float64       \n",
      " 4   Low     152 non-null    float64       \n",
      " 5   Volume  152 non-null    object        \n",
      " 6   Chg%    152 non-null    float64       \n",
      " 7   Nifty   152 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(6), object(1)\n",
      "memory usage: 9.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "QX5WxYgaw129",
    "outputId": "a8f8848d-0507-4bcb-c967-699243af832a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-649f8f10-26b7-4ad8-9396-7f9c5822c01a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Chg%</th>\n",
       "      <th>Nifty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-649f8f10-26b7-4ad8-9396-7f9c5822c01a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-649f8f10-26b7-4ad8-9396-7f9c5822c01a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-649f8f10-26b7-4ad8-9396-7f9c5822c01a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      Date  Price   Open   High    Low  Volume   Chg%  Nifty\n",
       "0    False  False  False  False  False   False  False  False\n",
       "1    False  False  False  False  False   False  False  False\n",
       "2    False  False  False  False  False   False  False  False\n",
       "3    False  False  False  False  False   False  False  False\n",
       "4    False  False  False  False  False   False  False  False\n",
       "..     ...    ...    ...    ...    ...     ...    ...    ...\n",
       "147  False  False  False  False  False   False  False  False\n",
       "148  False  False  False  False  False   False  False  False\n",
       "149  False  False  False  False  False   False  False  False\n",
       "150  False  False  False  False  False   False  False  False\n",
       "151  False  False  False  False  False   False  False  False\n",
       "\n",
       "[152 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WwcqePatw7-Q"
   },
   "outputs": [],
   "source": [
    "test_feature = [\"Open\", \"High\", \"Low\", \"Nifty\"]\n",
    "x_test = test[test_feature] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rz1v9quExDRu",
    "outputId": "41d030ed-651b-4c5b-94e3-472a658eb110"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ca7a43cc-5b67-4903-848b-0dc48261d052\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Nifty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.425</td>\n",
       "      <td>82.628</td>\n",
       "      <td>82.355</td>\n",
       "      <td>17321.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.588</td>\n",
       "      <td>82.634</td>\n",
       "      <td>82.365</td>\n",
       "      <td>17450.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.690</td>\n",
       "      <td>82.761</td>\n",
       "      <td>82.554</td>\n",
       "      <td>17303.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.871</td>\n",
       "      <td>82.951</td>\n",
       "      <td>82.627</td>\n",
       "      <td>17392.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.643</td>\n",
       "      <td>83.026</td>\n",
       "      <td>82.628</td>\n",
       "      <td>17465.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca7a43cc-5b67-4903-848b-0dc48261d052')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ca7a43cc-5b67-4903-848b-0dc48261d052 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ca7a43cc-5b67-4903-848b-0dc48261d052');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     Open    High     Low     Nifty\n",
       "0  82.425  82.628  82.355  17321.90\n",
       "1  82.588  82.634  82.365  17450.90\n",
       "2  82.690  82.761  82.554  17303.95\n",
       "3  82.871  82.951  82.627  17392.70\n",
       "4  82.643  83.026  82.628  17465.80"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f82EkrxUxHYs",
    "outputId": "1272feb2-6ccf-4a9d-9550-2d3abbf47a87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    82.350\n",
       "1    82.430\n",
       "2    82.640\n",
       "3    82.642\n",
       "4    82.897\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Price\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "TvXYjjbTxIge"
   },
   "outputs": [],
   "source": [
    "y = test[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMM0G2gXxLYu",
    "outputId": "57867fb7-9d1d-4cd7-beaf-fc77e75f037c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3363\n",
      "Test Loss: 0.3363250195980072\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "test_loss = model.evaluate(x_test, y)\n",
    "print('Test Loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O85r08FY7YOc",
    "outputId": "1e1b4cf5-ebbd-4d81-d076-5e6ca842f3cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[81.8568  ],\n",
       "       [81.92168 ],\n",
       "       [82.05113 ],\n",
       "       [82.20073 ],\n",
       "       [82.14842 ],\n",
       "       [82.12273 ],\n",
       "       [82.23741 ],\n",
       "       [82.15044 ],\n",
       "       [82.09679 ],\n",
       "       [82.15996 ],\n",
       "       [82.125534],\n",
       "       [82.26213 ],\n",
       "       [82.13713 ],\n",
       "       [82.04607 ],\n",
       "       [81.91167 ],\n",
       "       [81.988144],\n",
       "       [82.06206 ],\n",
       "       [82.155075],\n",
       "       [81.9196  ],\n",
       "       [81.46184 ],\n",
       "       [81.29704 ],\n",
       "       [81.24272 ],\n",
       "       [81.160934],\n",
       "       [81.00145 ],\n",
       "       [80.97514 ],\n",
       "       [81.05162 ],\n",
       "       [80.9962  ],\n",
       "       [80.55791 ],\n",
       "       [80.64055 ],\n",
       "       [80.81566 ],\n",
       "       [81.008224],\n",
       "       [81.15129 ],\n",
       "       [80.82646 ],\n",
       "       [80.69182 ],\n",
       "       [80.950485],\n",
       "       [81.08159 ],\n",
       "       [81.46745 ],\n",
       "       [81.68303 ],\n",
       "       [81.964584],\n",
       "       [82.06975 ],\n",
       "       [82.19389 ],\n",
       "       [82.207565],\n",
       "       [82.09111 ],\n",
       "       [82.13115 ],\n",
       "       [82.24309 ],\n",
       "       [82.24541 ],\n",
       "       [82.1541  ],\n",
       "       [82.15605 ],\n",
       "       [82.23796 ],\n",
       "       [82.228745],\n",
       "       [82.18291 ],\n",
       "       [82.09599 ],\n",
       "       [82.14726 ],\n",
       "       [82.212814],\n",
       "       [82.07146 ],\n",
       "       [82.01128 ],\n",
       "       [82.08696 ],\n",
       "       [81.96037 ],\n",
       "       [81.71709 ],\n",
       "       [81.768845],\n",
       "       [81.90044 ],\n",
       "       [81.59062 ],\n",
       "       [80.91777 ],\n",
       "       [80.72783 ],\n",
       "       [80.63628 ],\n",
       "       [80.9937  ],\n",
       "       [81.07146 ],\n",
       "       [81.18364 ],\n",
       "       [81.076584],\n",
       "       [81.11601 ],\n",
       "       [81.20073 ],\n",
       "       [81.155685],\n",
       "       [81.163864],\n",
       "       [81.05681 ],\n",
       "       [81.02409 ],\n",
       "       [80.71855 ],\n",
       "       [80.517624],\n",
       "       [80.245895],\n",
       "       [80.1541  ],\n",
       "       [80.79497 ],\n",
       "       [80.840256],\n",
       "       [81.50383 ],\n",
       "       [81.89751 ],\n",
       "       [82.2672  ],\n",
       "       [82.111374],\n",
       "       [82.12871 ],\n",
       "       [81.93718 ],\n",
       "       [81.79033 ],\n",
       "       [81.61528 ],\n",
       "       [82.07573 ],\n",
       "       [82.081406],\n",
       "       [82.21837 ],\n",
       "       [82.3206  ],\n",
       "       [81.95592 ],\n",
       "       [81.593185],\n",
       "       [81.70622 ],\n",
       "       [81.64421 ],\n",
       "       [81.707565],\n",
       "       [81.650925],\n",
       "       [81.72447 ],\n",
       "       [81.95097 ],\n",
       "       [81.80107 ],\n",
       "       [81.17601 ],\n",
       "       [80.90312 ],\n",
       "       [81.04491 ],\n",
       "       [80.87053 ],\n",
       "       [81.06737 ],\n",
       "       [81.14653 ],\n",
       "       [80.882   ],\n",
       "       [80.86076 ],\n",
       "       [80.46562 ],\n",
       "       [79.97575 ],\n",
       "       [79.333786],\n",
       "       [79.15953 ],\n",
       "       [79.18059 ],\n",
       "       [79.246506],\n",
       "       [79.07829 ],\n",
       "       [79.02336 ],\n",
       "       [78.8499  ],\n",
       "       [79.04906 ],\n",
       "       [79.08836 ],\n",
       "       [79.18938 ],\n",
       "       [79.29997 ],\n",
       "       [79.2885  ],\n",
       "       [79.34013 ],\n",
       "       [79.21159 ],\n",
       "       [78.99724 ],\n",
       "       [79.2758  ],\n",
       "       [79.45891 ],\n",
       "       [79.32634 ],\n",
       "       [79.31993 ],\n",
       "       [79.29295 ],\n",
       "       [79.2957  ],\n",
       "       [79.33324 ],\n",
       "       [79.27995 ],\n",
       "       [79.00261 ],\n",
       "       [78.77275 ],\n",
       "       [78.9594  ],\n",
       "       [79.12834 ],\n",
       "       [78.75908 ],\n",
       "       [78.885666],\n",
       "       [78.984055],\n",
       "       [78.67241 ],\n",
       "       [78.80144 ],\n",
       "       [78.30205 ],\n",
       "       [78.284164],\n",
       "       [78.59007 ],\n",
       "       [78.929306],\n",
       "       [79.18376 ],\n",
       "       [79.29558 ],\n",
       "       [79.19914 ],\n",
       "       [79.21721 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygJqfrft8rqW",
    "outputId": "bc4a4b1a-2e7d-445b-97e4-04c75fa7025a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      82.350\n",
       "1      82.430\n",
       "2      82.640\n",
       "3      82.642\n",
       "4      82.897\n",
       "        ...  \n",
       "147    79.336\n",
       "148    79.626\n",
       "149    79.845\n",
       "150    79.843\n",
       "151    79.691\n",
       "Name: Price, Length: 152, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wA9zKV6_8trK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
